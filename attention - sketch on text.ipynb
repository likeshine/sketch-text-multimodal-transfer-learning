{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1637076985885
    },
    "id": "3K7u2BRsyVPT"
   },
   "outputs": [],
   "source": [
    "##https://colab.research.google.com/github/trekhleb/machine-learning-experiments/blob/master/experiments/image_recognition_cnn/image_recognition_cnn.ipynb#scrollTo=ZTO-30-IMfK3\n",
    "##how to feed grayscale images to pretrained models which requires 3 input channels:\n",
    "##https://stackoverflow.com/questions/51995977/how-can-i-use-a-pre-trained-neural-network-with-grayscale-images\n",
    "##attention ref: https://github.com/dt024/RIVF2021_fakenews\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from official import nlp\n",
    "import official.nlp.optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aLYSD_orY8Pt"
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow==2.7.3\n",
    "# !pip install -q tf-models-official==2.7.0\n",
    "# !pip install tensorflow_hub\n",
    "# !pip install tensorflow_text\n",
    "# # !pip install keras-lr-multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Cw71STqsYf0c"
   },
   "outputs": [],
   "source": [
    "# pip list -v "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xcY7k3opmr7_"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8eGwGQ7dyVPW",
    "outputId": "d4e84d05-6072-4967-a04f-2b476e84cb42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 2 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0:2], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "y4OfBhDgYF-_"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "wVND9sRYyh-B"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gather": {
     "logged": 1637077095460
    },
    "id": "pxpkHzj3yVPX",
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sketch = pd.read_csv('data/sketch_drawing.csv')\n",
    "\n",
    "# var = 'Unique_expert'\n",
    "var = 'Drawing_expert'\n",
    "# var = 'Useful_expert'\n",
    "# var = 'Elegence_expert'\n",
    "# var = 'Creativity_expert'\n",
    "\n",
    "mapping1 = {'Creativity_expert': 'Creativity',\n",
    "                       'Useful_expert': 'Useful',\n",
    "                       'Unique_expert': 'Unique',\n",
    "                       'Drawing_expert': 'Drawing',\n",
    "                       'Elegence_expert': 'Elegence',}\n",
    "mapping = {'Creativity_expert': 'Creativity_expert_round',\n",
    "                       'Useful_expert': 'Useful_expert_round',\n",
    "                       'Unique_expert': 'Unique_expert_round',\n",
    "                       'Drawing_expert': 'Drawing_expert_round',\n",
    "                       'Elegence_expert': 'Elegence_expert_round',}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1637078107788
    },
    "id": "pkdOkCFOyVPY",
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# sketch1 = pd.read_csv('data/sketch_drawing.csv')\n",
    "sketch1 = pd.read_csv('data/sketch_drawing.csv')\n",
    "sketch_emb = np.loadtxt('sketch emb-'+var) \n",
    "# sketchs = [sketch[i] for i in sketch.keys()]\n",
    "train_df = sketch1[sketch1['set2_'+var] == 'train'] \n",
    "val_df = sketch1[sketch1['set2_'+var] == 'val'] \n",
    "test_df = sketch1[sketch1['set2_'+var] == 'test'] \n",
    "\n",
    "train_emb = np.array([sketch_emb[i] for i in train_df.index])\n",
    "val_emb = np.array([sketch_emb[i] for i in val_df.index])\n",
    "test_emb = np.array([sketch_emb[i] for i in test_df.index])\n",
    "\n",
    "##to add\n",
    "sketch1 = sketch1.astype({\"text\": str})\n",
    "text = list(sketch1['text'])\n",
    "train_text = [text[i] for i in train_df.index]\n",
    "val_text = [text[i] for i in val_df.index]\n",
    "test_text = [text[i] for i in test_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2Lpd8sVlyVPY"
   },
   "outputs": [],
   "source": [
    "train_cost = train_df[var]\n",
    "val_cost = val_df[var]\n",
    "test_cost = test_df[var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "BHWfxDFtyVPZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.signal.windows import triang\n",
    "\n",
    "def get_bin_idx(x):\n",
    "    return min(int(x * np.float32(10)), 99)\n",
    "\n",
    "def get_lds_kernel_window(kernel, ks, sigma):\n",
    "    assert kernel in ['gaussian', 'triang', 'laplace']\n",
    "    half_ks = (ks - 1) // 2\n",
    "    if kernel == 'gaussian':\n",
    "        base_kernel = [0.] * half_ks + [1.] + [0.] * half_ks\n",
    "        kernel_window = gaussian_filter1d(base_kernel, sigma=sigma) / max(gaussian_filter1d(base_kernel, sigma=sigma))\n",
    "    elif kernel == 'triang':\n",
    "        kernel_window = triang(ks)\n",
    "    else:\n",
    "        laplace = lambda x: np.exp(-abs(x) / sigma) / (2. * sigma)\n",
    "        kernel_window = list(map(laplace, np.arange(-half_ks, half_ks + 1))) / max(map(laplace, np.arange(-half_ks, half_ks + 1)))\n",
    "\n",
    "    return kernel_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "g8i8s18AyVPZ"
   },
   "outputs": [],
   "source": [
    "# https://github.com/YyzHarry/imbalanced-regression''\n",
    "\n",
    "from collections import Counter\n",
    "from scipy.ndimage import convolve1d\n",
    "\n",
    "for i in [0]:\n",
    "    # preds, labels: [Ns,], \"Ns\" is the number of total samples\n",
    "#     preds, labels = train_df, train_cost1[var]\n",
    "    labels = train_cost\n",
    "    # assign each label to its corresponding bin (start from 0)\n",
    "    # with your defined get_bin_idx(), return bin_index_per_label: [Ns,] \n",
    "    bin_index_per_label = [get_bin_idx(label) for label in labels]\n",
    "\n",
    "    # calculate empirical (original) label distribution: [Nb,]\n",
    "    # \"Nb\" is the number of bins\n",
    "    Nb = max(bin_index_per_label) + 1\n",
    "    num_samples_of_bins = dict(Counter(bin_index_per_label))\n",
    "    emp_label_dist = [num_samples_of_bins.get(i, 0) for i in range(Nb)]\n",
    "\n",
    "    # lds_kernel_window: [ks,], here for example, we use gaussian, ks=5, sigma=2\n",
    "    lds_kernel_window = get_lds_kernel_window(kernel='gaussian', ks=5, sigma=2)\n",
    "    # calculate effective label distribution: [Nb,]\n",
    "    eff_label_dist = convolve1d(np.array(emp_label_dist), weights=lds_kernel_window, mode='constant')\n",
    "\n",
    "    # Use re-weighting based on effective label distribution, sample-wise weights: [Ns,]\n",
    "    eff_num_per_label = [eff_label_dist[bin_idx] for bin_idx in bin_index_per_label]\n",
    "    weights = [np.float32(1 / x) for x in eff_num_per_label]\n",
    "    # # calculate loss\n",
    "    # loss = weighted_mse_loss(preds, labels, weights=weights)                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lz88jgMryVPa",
    "outputId": "d1a63ce6-91a0-409c-e674-743b3adbc215"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
     ]
    }
   ],
   "source": [
    "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'\n",
    "# bert_model_name = 'small_bert/bert_en_uncased_L-4_H-768_A-12'\n",
    "\n",
    "map_name_to_handle = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/google/electra_small/2',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/google/electra_base/2',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "3xRUTVpUyVPb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tNSM5g6fZYMf",
    "outputId": "302de616-a225-4288-eea2-9f1229cf5bab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['default', 'sequence_output', 'pooled_output', 'encoder_outputs'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = list(sketch1['text'])\n",
    "text_preprocessed = bert_preprocess_model(text[0:1])\n",
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)\n",
    "bert_results = bert_model(text_preprocessed)\n",
    "bert_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# bert_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ouJDu_BqjdC",
    "outputId": "a3c90c4f-3d6d-4f66-f3e9-0f6a3c36e556"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 128, 512])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_results['encoder_outputs'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "R_wS0cgAyVPb"
   },
   "outputs": [],
   "source": [
    "# text_preprocessed_train = bert_preprocess_model(train_text)\n",
    "# text_preprocessed_val = bert_preprocess_model(val_text)\n",
    "# text_preprocessed_test = bert_preprocess_model(test_text)\n",
    "\n",
    "# text_test = ['this is such an amazing movie!']\n",
    "# text_preprocessed = bert_preprocess_model(text_test)\n",
    "\n",
    "# print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "# print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "# print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "# print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "# print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "eNQbpBIByT8I"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras import Model, Input, layers, regularizers\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras import activations\n",
    "from official.nlp import optimization \n",
    "\n",
    "epochs = 1000\n",
    "steps_per_epoch = 56\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "##unique: 0.005, drawing: 0.005, elegance: 0.05, creativity: 0.05, useful: 0.1\n",
    "a = 0.01\n",
    "if var == 'Unique_expert' or var == 'Drawing_expert':\n",
    "    a = 0.005\n",
    "# elif var == 'Creativity_expert':\n",
    "#     a = 0.005\n",
    "# elif var == 'Useful_expert':\n",
    "#     a = 0.01\n",
    "num_warmup_steps = int(a*num_train_steps)\n",
    "init_lr = 2e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')\n",
    "\n",
    "merge = []\n",
    "text_input = Input(shape=(), dtype=tf.string, name='text')\n",
    "input_tensor = Input(shape=1048, name='input')\n",
    "\n",
    "# preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "# encoder_inputs = preprocessing_layer(text_input)\n",
    "# encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "# outputs = encoder(encoder_inputs)\n",
    "\n",
    "# sequence_output_1 = outputs['encoder_outputs'][0][:,0,:]\n",
    "# sequence_output_1 = layers.BatchNormalization()(sequence_output_1)\n",
    "# sequence_output_1 = layers.Activation('tanh')(sequence_output_1)\n",
    "# sequence_output_2 = outputs['encoder_outputs'][1][:,0,:]\n",
    "# sequence_output_2 = layers.BatchNormalization()(sequence_output_2)\n",
    "# sequence_output_2 = layers.Activation('tanh')(sequence_output_2)\n",
    "# sequence_output_3 = outputs['encoder_outputs'][2][:,0,:]\n",
    "# sequence_output_3 = layers.BatchNormalization()(sequence_output_3)\n",
    "# sequence_output_3 = layers.Activation('tanh')(sequence_output_3)\n",
    "# sequence_output_4 = outputs['encoder_outputs'][3][:,0,:]\n",
    "# sequence_output_4 = layers.BatchNormalization()(sequence_output_4)\n",
    "# sequence_output_4 = layers.Activation('tanh')(sequence_output_4)\n",
    "# sequence_output_1 = layers.Reshape((-1,sequence_output_4.shape[-1]))(sequence_output_1)\n",
    "# sequence_output_2 = layers.Reshape((-1,sequence_output_4.shape[-1]))(sequence_output_2)\n",
    "# sequence_output_3 = layers.Reshape((-1,sequence_output_4.shape[-1]))(sequence_output_3)\n",
    "# sequence_output_4 = layers.Reshape((-1,sequence_output_4.shape[-1]))(sequence_output_4)\n",
    "# # print (sequence_output_4.shape)\n",
    "# sequence_output = layers.Concatenate(axis=1)([sequence_output_1, sequence_output_2, sequence_output_3, sequence_output_4])\n",
    "# # print (sequence_output.shape)\n",
    "\n",
    "model_name = 'model weight/'+var+'/new text-'+var+'-best.h5'\n",
    "base_model = load_model(model_name, custom_objects={'KerasLayer':hub.KerasLayer,'AdamWeightDecay': optimizer})\n",
    "for layer in base_model.layers:\n",
    "    layer._name = layer._name + \"_a\"\n",
    "\n",
    "sequence_output_1 = base_model.layers[2].output['encoder_outputs'][0][:,0,:]\n",
    "sequence_output_1 = layers.BatchNormalization()(sequence_output_1)\n",
    "sequence_output_1 = layers.Activation('tanh')(sequence_output_1)\n",
    "sequence_output_2 = base_model.layers[2].output['encoder_outputs'][1][:,0,:]\n",
    "sequence_output_2 = layers.BatchNormalization()(sequence_output_2)\n",
    "sequence_output_2 = layers.Activation('tanh')(sequence_output_2)\n",
    "sequence_output_3 = base_model.layers[2].output['encoder_outputs'][2][:,0,:]\n",
    "sequence_output_3 = layers.BatchNormalization()(sequence_output_3)\n",
    "sequence_output_3 = layers.Activation('tanh')(sequence_output_3)\n",
    "sequence_output_4 = base_model.layers[2].output['encoder_outputs'][3][:,0,:]\n",
    "sequence_output_4 = layers.BatchNormalization()(sequence_output_4)\n",
    "sequence_output_4 = layers.Activation('tanh')(sequence_output_4)\n",
    "sequence_output_1 = layers.Reshape((-1,sequence_output_4.shape[-1]))(sequence_output_1)\n",
    "sequence_output_2 = layers.Reshape((-1,sequence_output_4.shape[-1]))(sequence_output_2)\n",
    "sequence_output_3 = layers.Reshape((-1,sequence_output_4.shape[-1]))(sequence_output_3)\n",
    "sequence_output_4 = layers.Reshape((-1,sequence_output_4.shape[-1]))(sequence_output_4)\n",
    "# print (sequence_output_4.shape)\n",
    "sequence_output = layers.Concatenate(axis=1)([sequence_output_1, sequence_output_2, sequence_output_3, sequence_output_4])\n",
    "# print (sequence_output.shape)\n",
    "\n",
    "drop_rate = 0.1\n",
    "drop_rate1 = 0.3\n",
    "final_hid = 64\n",
    "head = 1\n",
    "att_layers = 1\n",
    "att_hid = 64\n",
    "\n",
    "sketch_append = input_tensor\n",
    "sketch_append = layers.Activation('tanh')(sketch_append)\n",
    "sketch_append = layers.Dropout(drop_rate1)(sketch_append)\n",
    "\n",
    "text_append =  base_model.layers[2].output['pooled_output']\n",
    "text_append1 =  base_model.layers[-3].output\n",
    "\n",
    "##With attention - sketch on text\n",
    "inpAttText_key = sequence_output\n",
    "inpAttText_query = sketch_append\n",
    "for layer in range(att_layers):\n",
    "    att_text = []\n",
    "    concat_key = []\n",
    "    for _ in range(head):\n",
    "        img_query = layers.Dense(att_hid/head, use_bias=False)(inpAttText_query)\n",
    "        img_query1 = layers.BatchNormalization()(img_query)\n",
    "        img_query1 = layers.Activation('relu')(img_query1)\n",
    "        # img_query1 = layers.Dropout(drop_rate1)(img_query1)\n",
    "        # img_query = layers.BatchNormalization()(img_query)\n",
    "        # img_query = layers.Activation('tanh')(img_query)\n",
    "        img_query = layers.Dropout(drop_rate)(img_query)\n",
    "        \n",
    "        text_key = layers.Dense(att_hid/head, use_bias=False)(inpAttText_key)\n",
    "        text_key1 = layers.BatchNormalization()(text_key)\n",
    "        text_key1 = layers.Activation('relu')(text_key1)\n",
    "        # text_key1 = layers.Dropout(drop_rate1)(text_key1)\n",
    "        # text_key = layers.BatchNormalization()(text_key)\n",
    "        # text_key = layers.Activation('tanh')(text_key)\n",
    "        text_key = layers.Dropout(drop_rate)(text_key)\n",
    "        \n",
    "        text_value = layers.Dense(att_hid/head, use_bias=False)(inpAttText_key)\n",
    "        text_value = layers.Dropout(drop_rate)(text_value)\n",
    "        \n",
    "        # print (img_query.shape)\n",
    "        # print (text_key.shape)\n",
    "        attention = layers.Dot(axes=(1,2))([img_query, text_key])\n",
    "        attention = layers.Lambda(lambda x: x[0]/x[1])([attention,np.sqrt(att_hid/head)])\n",
    "        attention = layers.Activation(\"softmax\")(attention)\n",
    "        # print (attention.shape)\n",
    "        # print (text_value.shape)\n",
    "        head_att_text = layers.Dot(axes=(1,1))([attention, text_value])\n",
    "        att_text = head_att_text\n",
    "        concat_key = text_key\n",
    "    # att_text = Concatenate(axis=1)(att_text)\n",
    "    # att_text = Dense(512, use_bias=False)(att_text)\n",
    "    # att_text = Dropout(0.3)(att_text)\n",
    "    # att_text = Add()([att_text, inpAttText_query])\n",
    "    # att_text = LayerNormalization()(att_text)\n",
    "    # att_text2 = Dense(1024,activation='relu')(att_text)\n",
    "    # att_text2 = Dense(512)(att_text)\n",
    "    # att_text2 = Dropout(0.1)(att_text2)\n",
    "    # att_text = Add()([att_text, att_text2])\n",
    "    # att_text = LayerNormalization()(att_text)\n",
    "\n",
    "    # concat_key = Concatenate(axis=1)(concat_key)\n",
    "    # concat_key = Dense(512)(concat_key)\n",
    "    # concat_key = Dropout(0.3)(concat_key)\n",
    "    # concat_key = Add()([concat_key, inpAttText_key])\n",
    "    # concat_key = LayerNormalization()(concat_key)\n",
    "    # concat_key2 = Dense(1024,activation='relu')(concat_key)\n",
    "    # concat_key2 = Dense(512)(concat_key)\n",
    "    # concat_key2 = Dropout(0.1)(concat_key2)\n",
    "    # concat_key = Add()([concat_key, concat_key2])\n",
    "    # concat_key = LayerNormalization()(concat_key)\n",
    "    \n",
    "    inpAttText_query = att_text\n",
    "    inpAttText_key = concat_key\n",
    "    \n",
    "merge.append(att_text)\n",
    "merge.append(img_query1)\n",
    "# print (img_query1.shape)\n",
    "# text_key1 = layers.Reshape((-1,256))(text_key1)\n",
    "# merge.append(text_key1)\n",
    "# print (text_key1.shape)\n",
    "merge.append(text_append1)\n",
    "\n",
    "l_merge = layers.Concatenate(axis=1)(merge)\n",
    "l_merge = layers.Dropout(drop_rate1)(l_merge)\n",
    "\n",
    "out4 = layers.Dense(1, activation='relu', name='out4')(l_merge)\n",
    "model = Model([base_model.input,input_tensor], out4)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics= tf.keras.metrics.RootMeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "1eLZlR3MyVPd"
   },
   "outputs": [],
   "source": [
    "##definition of callbacks\n",
    "epochs = 1000\n",
    "steps_per_epoch = 37\n",
    "batch_size = 24\n",
    "\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "#     patience=5,\n",
    "    monitor=\"val_loss\",\n",
    "    restore_best_weights=True,\n",
    "    verbose=1)\n",
    "\n",
    "# # lr = 0.0000003\n",
    "# lr = 0.00001\n",
    "# def decay(epoch, steps=100):\n",
    "# #     initial_lrate = 0.0001\n",
    "#     initial_lrate = lr\n",
    "# #     initial_lrate = 0.0000003\n",
    "# #     drop = 0.9\n",
    "#     drop = 1\n",
    "#     epochs_drop = 4\n",
    "#     lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "#     return lrate\n",
    "# lr_sc = LearningRateScheduler(decay, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "rJUTgLiNPJQ1"
   },
   "outputs": [],
   "source": [
    "# num_warmup_steps = 0\n",
    "# init_lr = 1.5e-5\n",
    "# optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "#                                           num_train_steps=num_train_steps,\n",
    "#                                           num_warmup_steps=num_warmup_steps,\n",
    "#                                           optimizer_type='adamw')\n",
    "# model.compile(optimizer=optimizer,\n",
    "#               loss=tf.keras.losses.MeanSquaredError(),\n",
    "#               metrics= tf.keras.metrics.RootMeanSquaredError())\n",
    "\n",
    "# early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "#     patience=5,\n",
    "# #     patience=5,\n",
    "#     monitor=\"val_loss\",\n",
    "#     restore_best_weights=True,\n",
    "#     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jIYL1FPgyVPd",
    "outputId": "6ad61b7e-fa9c-41c9-ce87-9ed0263b08c6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "37/37 [==============================] - 10s 258ms/step - loss: 0.0047 - root_mean_squared_error: 0.6151 - val_loss: 0.8722 - val_root_mean_squared_error: 0.9339\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 9s 255ms/step - loss: 0.0055 - root_mean_squared_error: 0.6547 - val_loss: 0.8856 - val_root_mean_squared_error: 0.9411\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 10s 263ms/step - loss: 0.0057 - root_mean_squared_error: 0.6434 - val_loss: 1.0388 - val_root_mean_squared_error: 1.0192\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 10s 260ms/step - loss: 0.0056 - root_mean_squared_error: 0.6513 - val_loss: 0.8817 - val_root_mean_squared_error: 0.9390\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 10s 263ms/step - loss: 0.0058 - root_mean_squared_error: 0.6296 - val_loss: 0.9560 - val_root_mean_squared_error: 0.9778\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 10s 265ms/step - loss: 0.0052 - root_mean_squared_error: 0.6081 - val_loss: 0.9101 - val_root_mean_squared_error: 0.9540\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 10s 263ms/step - loss: 0.0053 - root_mean_squared_error: 0.6467 - val_loss: 0.9668 - val_root_mean_squared_error: 0.9833\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 10s 267ms/step - loss: 0.0049 - root_mean_squared_error: 0.6088 - val_loss: 0.9268 - val_root_mean_squared_error: 0.9627\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - 10s 264ms/step - loss: 0.0052 - root_mean_squared_error: 0.6254 - val_loss: 0.9025 - val_root_mean_squared_error: 0.9500\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - 10s 266ms/step - loss: 0.0042 - root_mean_squared_error: 0.6111 - val_loss: 0.9362 - val_root_mean_squared_error: 0.9676\n",
      "Epoch 11/1000\n",
      "37/37 [==============================] - 10s 267ms/step - loss: 0.0055 - root_mean_squared_error: 0.6227 - val_loss: 1.0034 - val_root_mean_squared_error: 1.0017\n",
      "Epoch 12/1000\n",
      "37/37 [==============================] - 9s 251ms/step - loss: 0.0049 - root_mean_squared_error: 0.6272 - val_loss: 0.9601 - val_root_mean_squared_error: 0.9798\n",
      "Epoch 13/1000\n",
      "37/37 [==============================] - 10s 260ms/step - loss: 0.0048 - root_mean_squared_error: 0.6249 - val_loss: 0.9261 - val_root_mean_squared_error: 0.9623\n",
      "Epoch 14/1000\n",
      "37/37 [==============================] - 10s 267ms/step - loss: 0.0046 - root_mean_squared_error: 0.6044 - val_loss: 0.9216 - val_root_mean_squared_error: 0.9600\n",
      "Epoch 15/1000\n",
      "37/37 [==============================] - 10s 264ms/step - loss: 0.0056 - root_mean_squared_error: 0.6486 - val_loss: 0.9224 - val_root_mean_squared_error: 0.9604\n",
      "Epoch 16/1000\n",
      "37/37 [==============================] - 10s 258ms/step - loss: 0.0045 - root_mean_squared_error: 0.5981 - val_loss: 0.9608 - val_root_mean_squared_error: 0.9802\n",
      "Epoch 17/1000\n",
      "37/37 [==============================] - 9s 254ms/step - loss: 0.0052 - root_mean_squared_error: 0.6102 - val_loss: 0.9561 - val_root_mean_squared_error: 0.9778\n",
      "Epoch 18/1000\n",
      "37/37 [==============================] - 10s 269ms/step - loss: 0.0054 - root_mean_squared_error: 0.6401 - val_loss: 0.9870 - val_root_mean_squared_error: 0.9935\n",
      "Epoch 19/1000\n",
      "20/37 [===============>..............] - ETA: 4s - loss: 0.0044 - root_mean_squared_error: 0.5929"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m training_history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_text\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_emb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;43;03m#     x = x_train,\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# x = tf.constant(train_text),\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mout4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_cost\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mout4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_text\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_emb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;43;03m#                      x_val,\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# tf.constant(val_text),\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mout4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_cost\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping_callback\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-transf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-transf\\lib\\site-packages\\keras\\engine\\training.py:1216\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1209\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1210\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1211\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1212\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1213\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1214\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1215\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1216\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1217\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1218\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-transf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-transf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:910\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    907\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    909\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 910\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    912\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    913\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-transf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:942\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    939\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    940\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    941\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 942\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-transf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3130\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3127\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   3128\u001b[0m   (graph_function,\n\u001b[0;32m   3129\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-transf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1959\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1955\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1957\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1958\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1959\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1960\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1961\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1962\u001b[0m     args,\n\u001b[0;32m   1963\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1964\u001b[0m     executing_eagerly)\n\u001b[0;32m   1965\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-transf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:598\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    604\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    605\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    606\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    607\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    610\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    611\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-transf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 58\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     61\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_history = model.fit(\n",
    "    x = [tf.constant(train_text),train_emb],\n",
    "#     x = x_train,\n",
    "    # x = tf.constant(train_text),\n",
    "    y = {'out4':np.array(train_cost)},\n",
    "    sample_weight={'out4': np.array(weights)},\n",
    "    epochs=epochs,\n",
    "    batch_size = batch_size,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=(\n",
    "        [tf.constant(val_text),val_emb],\n",
    "#                      x_val,\n",
    "        # tf.constant(val_text),\n",
    "        {'out4':np.array(val_cost)}),\n",
    "    callbacks=[early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "pl4_VMfLyVPe"
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "n = 2\n",
    "# a = 0.5\n",
    "output = pd.DataFrame()\n",
    "# test_results0 = base_model1.predict(x_test)\n",
    "# test_results0 = base_model2.predict(test_embedding)\n",
    "\n",
    "# test_results0 = model.predict([x_test,test_embedding])\n",
    "# test_results0 = model.predict(x_test)\n",
    "test_results0 = model.predict([tf.constant(test_text),test_emb])\n",
    "test_result= test_results0.reshape(len(test_text)).tolist()\n",
    "test_cost = test_df[var]\n",
    "\n",
    "difference_array = np.subtract(test_result, test_cost)\n",
    "squared_array = np.square(difference_array)\n",
    "mse = squared_array.mean()\n",
    "\n",
    "correlation_matrix = np.corrcoef(test_cost, test_result)\n",
    "correlation_xy = correlation_matrix[0,1]\n",
    "r_squared = correlation_xy**2\n",
    "\n",
    "output.loc[idx,'warm up'] = a\n",
    "output.loc[idx,'var'] = var\n",
    "output.loc[idx,'lr'] = init_lr\n",
    "output.loc[idx,'mse'] = mse\n",
    "output.loc[idx,'r^2'] = r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "KSIBemXcyVPe",
    "outputId": "fe371daf-24e2-4b4a-b4e9-47dd103e8dd6",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>warm up</th>\n",
       "      <th>var</th>\n",
       "      <th>lr</th>\n",
       "      <th>mse</th>\n",
       "      <th>r^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005</td>\n",
       "      <td>Drawing_expert</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.739586</td>\n",
       "      <td>0.359981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   warm up             var        lr       mse       r^2\n",
       "0    0.005  Drawing_expert  0.000015  0.739586  0.359981"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDnbFzlPLcGt"
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "FYTeMDeYyVPf",
    "outputId": "cec390ed-7a77-4820-d415-0fea7a2b25a4"
   },
   "outputs": [],
   "source": [
    "##save and load models\n",
    "##https://stackoverflow.com/questions/46610732/how-to-freeze-some-layers-when-fine-tune-resnet50\n",
    "# a = 1\n",
    "\n",
    "# var = 'Unique_expert'\n",
    "# var = 'Drawing_expert'\n",
    "# var = 'Useful_expert'\n",
    "# var = 'Elegence_expert'\n",
    "# var = 'Creativity_expert'\n",
    "\n",
    "model_name = 'model weight/'+var+'/attend-text1_'+var+'-best.h5'\n",
    "# model_name = 'model weight/both_ratio-'+str(1)+'-'+var+'-best.h5'\n",
    "# model_name = 'model weight/'+var+'/simple_joint_ratio-'+str(a)+'-'+var+'-best.h5'\n",
    "# model_name = 'model weight/'+var+'/joint_lr-'+str(initial_lrate)+'-'+var+'-best.h5'\n",
    "# model.save(model_name, save_format='h5')\n",
    "# model.save_weights(model_name)\n",
    "\n",
    "# from keras.models import load_model\n",
    "# model = load_model(model_name)\n",
    "##for text model\n",
    "# model = load_model(model_name, custom_objects={'KerasLayer':hub.KerasLayer,'AdamWeightDecay': optimizer})\n",
    "##for joint model\n",
    "model.load_weights(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 275ms/step - loss: 0.0043 - root_mean_squared_error: 0.5971 - val_loss: 0.8865 - val_root_mean_squared_error: 0.9416\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 9s 255ms/step - loss: 0.0050 - root_mean_squared_error: 0.6311 - val_loss: 0.9322 - val_root_mean_squared_error: 0.9655\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 9s 252ms/step - loss: 0.0059 - root_mean_squared_error: 0.6595 - val_loss: 0.9753 - val_root_mean_squared_error: 0.9876\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 9s 249ms/step - loss: 0.0052 - root_mean_squared_error: 0.6462 - val_loss: 0.9226 - val_root_mean_squared_error: 0.9605\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 9s 251ms/step - loss: 0.0044 - root_mean_squared_error: 0.5984 - val_loss: 0.9053 - val_root_mean_squared_error: 0.9515\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0047 - root_mean_squared_error: 0.6297Restoring model weights from the end of the best epoch: 1.\n",
      "37/37 [==============================] - 10s 260ms/step - loss: 0.0047 - root_mean_squared_error: 0.6297 - val_loss: 0.9153 - val_root_mean_squared_error: 0.9567\n",
      "Epoch 00006: early stopping\n",
      "1\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 15s 289ms/step - loss: 0.0056 - root_mean_squared_error: 0.6185 - val_loss: 0.9356 - val_root_mean_squared_error: 0.9673\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 10s 271ms/step - loss: 0.0047 - root_mean_squared_error: 0.6102 - val_loss: 0.8891 - val_root_mean_squared_error: 0.9429\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 10s 262ms/step - loss: 0.0052 - root_mean_squared_error: 0.6009 - val_loss: 0.9200 - val_root_mean_squared_error: 0.9592\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 10s 264ms/step - loss: 0.0054 - root_mean_squared_error: 0.6452 - val_loss: 0.9333 - val_root_mean_squared_error: 0.9661\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 10s 264ms/step - loss: 0.0050 - root_mean_squared_error: 0.6471 - val_loss: 0.9218 - val_root_mean_squared_error: 0.9601\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 10s 264ms/step - loss: 0.0052 - root_mean_squared_error: 0.6255 - val_loss: 0.9121 - val_root_mean_squared_error: 0.9550\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0056 - root_mean_squared_error: 0.6213Restoring model weights from the end of the best epoch: 2.\n",
      "37/37 [==============================] - 10s 261ms/step - loss: 0.0056 - root_mean_squared_error: 0.6213 - val_loss: 0.9092 - val_root_mean_squared_error: 0.9535\n",
      "Epoch 00007: early stopping\n",
      "2\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 15s 284ms/step - loss: 0.0053 - root_mean_squared_error: 0.6274 - val_loss: 0.9302 - val_root_mean_squared_error: 0.9644\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 10s 266ms/step - loss: 0.0048 - root_mean_squared_error: 0.6241 - val_loss: 0.9546 - val_root_mean_squared_error: 0.9770\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 10s 268ms/step - loss: 0.0051 - root_mean_squared_error: 0.6461 - val_loss: 0.9519 - val_root_mean_squared_error: 0.9756\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 10s 270ms/step - loss: 0.0050 - root_mean_squared_error: 0.6122 - val_loss: 0.9061 - val_root_mean_squared_error: 0.9519\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 10s 261ms/step - loss: 0.0049 - root_mean_squared_error: 0.6191 - val_loss: 0.9512 - val_root_mean_squared_error: 0.9753\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 10s 268ms/step - loss: 0.0057 - root_mean_squared_error: 0.6339 - val_loss: 0.9419 - val_root_mean_squared_error: 0.9705\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 10s 264ms/step - loss: 0.0055 - root_mean_squared_error: 0.6424 - val_loss: 0.9858 - val_root_mean_squared_error: 0.9929\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 10s 260ms/step - loss: 0.0049 - root_mean_squared_error: 0.6472 - val_loss: 0.9797 - val_root_mean_squared_error: 0.9898\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0048 - root_mean_squared_error: 0.6286Restoring model weights from the end of the best epoch: 4.\n",
      "37/37 [==============================] - 10s 264ms/step - loss: 0.0048 - root_mean_squared_error: 0.6286 - val_loss: 0.9910 - val_root_mean_squared_error: 0.9955\n",
      "Epoch 00009: early stopping\n",
      "3\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 280ms/step - loss: 0.0050 - root_mean_squared_error: 0.6043 - val_loss: 0.9016 - val_root_mean_squared_error: 0.9495\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 9s 252ms/step - loss: 0.0061 - root_mean_squared_error: 0.6424 - val_loss: 0.9415 - val_root_mean_squared_error: 0.9703\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 10s 257ms/step - loss: 0.0052 - root_mean_squared_error: 0.6088 - val_loss: 0.9778 - val_root_mean_squared_error: 0.9888\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 10s 257ms/step - loss: 0.0056 - root_mean_squared_error: 0.6051 - val_loss: 0.9418 - val_root_mean_squared_error: 0.9705\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 10s 258ms/step - loss: 0.0048 - root_mean_squared_error: 0.6067 - val_loss: 0.9361 - val_root_mean_squared_error: 0.9675\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0047 - root_mean_squared_error: 0.5996Restoring model weights from the end of the best epoch: 1.\n",
      "37/37 [==============================] - 10s 259ms/step - loss: 0.0047 - root_mean_squared_error: 0.5996 - val_loss: 0.9297 - val_root_mean_squared_error: 0.9642\n",
      "Epoch 00006: early stopping\n",
      "4\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 269ms/step - loss: 0.0048 - root_mean_squared_error: 0.6265 - val_loss: 0.9206 - val_root_mean_squared_error: 0.9595\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 10s 258ms/step - loss: 0.0052 - root_mean_squared_error: 0.6365 - val_loss: 0.8935 - val_root_mean_squared_error: 0.9453\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 10s 259ms/step - loss: 0.0062 - root_mean_squared_error: 0.6296 - val_loss: 0.9480 - val_root_mean_squared_error: 0.9737\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 9s 252ms/step - loss: 0.0045 - root_mean_squared_error: 0.5956 - val_loss: 0.9175 - val_root_mean_squared_error: 0.9579\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 10s 261ms/step - loss: 0.0053 - root_mean_squared_error: 0.6273 - val_loss: 0.9193 - val_root_mean_squared_error: 0.9588\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 9s 254ms/step - loss: 0.0054 - root_mean_squared_error: 0.6295 - val_loss: 0.9362 - val_root_mean_squared_error: 0.9676\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0054 - root_mean_squared_error: 0.6239Restoring model weights from the end of the best epoch: 2.\n",
      "37/37 [==============================] - 9s 255ms/step - loss: 0.0054 - root_mean_squared_error: 0.6239 - val_loss: 0.9366 - val_root_mean_squared_error: 0.9678\n",
      "Epoch 00007: early stopping\n",
      "5\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 16s 283ms/step - loss: 0.0066 - root_mean_squared_error: 0.6414 - val_loss: 0.9148 - val_root_mean_squared_error: 0.9565\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 10s 265ms/step - loss: 0.0049 - root_mean_squared_error: 0.6210 - val_loss: 0.9626 - val_root_mean_squared_error: 0.9811\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 10s 260ms/step - loss: 0.0047 - root_mean_squared_error: 0.6062 - val_loss: 1.0213 - val_root_mean_squared_error: 1.0106\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 10s 260ms/step - loss: 0.0053 - root_mean_squared_error: 0.6134 - val_loss: 0.9876 - val_root_mean_squared_error: 0.9938\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 9s 257ms/step - loss: 0.0060 - root_mean_squared_error: 0.6170 - val_loss: 0.9714 - val_root_mean_squared_error: 0.9856\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 10s 260ms/step - loss: 0.0064 - root_mean_squared_error: 0.6545 - val_loss: 0.9026 - val_root_mean_squared_error: 0.9501\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 10s 259ms/step - loss: 0.0045 - root_mean_squared_error: 0.5971 - val_loss: 0.9353 - val_root_mean_squared_error: 0.9671\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 10s 259ms/step - loss: 0.0055 - root_mean_squared_error: 0.6309 - val_loss: 0.9430 - val_root_mean_squared_error: 0.9711\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - 10s 268ms/step - loss: 0.0052 - root_mean_squared_error: 0.6178 - val_loss: 0.8728 - val_root_mean_squared_error: 0.9342\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - 10s 260ms/step - loss: 0.0050 - root_mean_squared_error: 0.6256 - val_loss: 0.9579 - val_root_mean_squared_error: 0.9787\n",
      "Epoch 11/1000\n",
      "37/37 [==============================] - 10s 264ms/step - loss: 0.0055 - root_mean_squared_error: 0.6219 - val_loss: 0.8735 - val_root_mean_squared_error: 0.9346\n",
      "Epoch 12/1000\n",
      "37/37 [==============================] - 9s 255ms/step - loss: 0.0054 - root_mean_squared_error: 0.6077 - val_loss: 0.8894 - val_root_mean_squared_error: 0.9431\n",
      "Epoch 13/1000\n",
      "37/37 [==============================] - 10s 259ms/step - loss: 0.0046 - root_mean_squared_error: 0.5897 - val_loss: 0.9144 - val_root_mean_squared_error: 0.9562\n",
      "Epoch 14/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0052 - root_mean_squared_error: 0.6232Restoring model weights from the end of the best epoch: 9.\n",
      "37/37 [==============================] - 10s 261ms/step - loss: 0.0052 - root_mean_squared_error: 0.6232 - val_loss: 0.9301 - val_root_mean_squared_error: 0.9644\n",
      "Epoch 00014: early stopping\n",
      "6\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 272ms/step - loss: 0.0053 - root_mean_squared_error: 0.6305 - val_loss: 0.8788 - val_root_mean_squared_error: 0.9374\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 9s 248ms/step - loss: 0.0060 - root_mean_squared_error: 0.6301 - val_loss: 0.9040 - val_root_mean_squared_error: 0.9508\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 9s 243ms/step - loss: 0.0047 - root_mean_squared_error: 0.6318 - val_loss: 0.9502 - val_root_mean_squared_error: 0.9748\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 9s 255ms/step - loss: 0.0055 - root_mean_squared_error: 0.6285 - val_loss: 0.8817 - val_root_mean_squared_error: 0.9390\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 9s 250ms/step - loss: 0.0063 - root_mean_squared_error: 0.6485 - val_loss: 0.9275 - val_root_mean_squared_error: 0.9631\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0052 - root_mean_squared_error: 0.6246Restoring model weights from the end of the best epoch: 1.\n",
      "37/37 [==============================] - 9s 247ms/step - loss: 0.0052 - root_mean_squared_error: 0.6246 - val_loss: 0.9977 - val_root_mean_squared_error: 0.9989\n",
      "Epoch 00006: early stopping\n",
      "7\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 268ms/step - loss: 0.0046 - root_mean_squared_error: 0.6031 - val_loss: 0.9591 - val_root_mean_squared_error: 0.9794\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 9s 254ms/step - loss: 0.0058 - root_mean_squared_error: 0.6463 - val_loss: 0.9677 - val_root_mean_squared_error: 0.9837\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 9s 251ms/step - loss: 0.0054 - root_mean_squared_error: 0.6192 - val_loss: 0.9824 - val_root_mean_squared_error: 0.9911\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 9s 255ms/step - loss: 0.0056 - root_mean_squared_error: 0.6171 - val_loss: 0.9127 - val_root_mean_squared_error: 0.9554\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 9s 254ms/step - loss: 0.0052 - root_mean_squared_error: 0.6446 - val_loss: 1.0344 - val_root_mean_squared_error: 1.0171\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 9s 255ms/step - loss: 0.0058 - root_mean_squared_error: 0.6412 - val_loss: 0.9223 - val_root_mean_squared_error: 0.9604\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 10s 258ms/step - loss: 0.0055 - root_mean_squared_error: 0.6307 - val_loss: 0.9310 - val_root_mean_squared_error: 0.9649\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 10s 262ms/step - loss: 0.0055 - root_mean_squared_error: 0.6368 - val_loss: 0.8956 - val_root_mean_squared_error: 0.9463\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - 9s 250ms/step - loss: 0.0053 - root_mean_squared_error: 0.6164 - val_loss: 0.9724 - val_root_mean_squared_error: 0.9861\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - 9s 251ms/step - loss: 0.0043 - root_mean_squared_error: 0.6168 - val_loss: 0.9324 - val_root_mean_squared_error: 0.9656\n",
      "Epoch 11/1000\n",
      "37/37 [==============================] - 9s 251ms/step - loss: 0.0049 - root_mean_squared_error: 0.5912 - val_loss: 0.9131 - val_root_mean_squared_error: 0.9556\n",
      "Epoch 12/1000\n",
      "37/37 [==============================] - 10s 257ms/step - loss: 0.0049 - root_mean_squared_error: 0.5963 - val_loss: 0.8992 - val_root_mean_squared_error: 0.9483\n",
      "Epoch 13/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0041 - root_mean_squared_error: 0.5867Restoring model weights from the end of the best epoch: 8.\n",
      "37/37 [==============================] - 10s 258ms/step - loss: 0.0041 - root_mean_squared_error: 0.5867 - val_loss: 0.9113 - val_root_mean_squared_error: 0.9546\n",
      "Epoch 00013: early stopping\n",
      "8\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 280ms/step - loss: 0.0059 - root_mean_squared_error: 0.6463 - val_loss: 0.9449 - val_root_mean_squared_error: 0.9721\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 10s 270ms/step - loss: 0.0059 - root_mean_squared_error: 0.6518 - val_loss: 0.8674 - val_root_mean_squared_error: 0.9314\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 9s 251ms/step - loss: 0.0055 - root_mean_squared_error: 0.6384 - val_loss: 0.9291 - val_root_mean_squared_error: 0.9639\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 9s 254ms/step - loss: 0.0053 - root_mean_squared_error: 0.6445 - val_loss: 0.9052 - val_root_mean_squared_error: 0.9514\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 9s 253ms/step - loss: 0.0057 - root_mean_squared_error: 0.6339 - val_loss: 0.9566 - val_root_mean_squared_error: 0.9781\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 10s 262ms/step - loss: 0.0044 - root_mean_squared_error: 0.6094 - val_loss: 0.9069 - val_root_mean_squared_error: 0.9523\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0054 - root_mean_squared_error: 0.6563Restoring model weights from the end of the best epoch: 2.\n",
      "37/37 [==============================] - 10s 265ms/step - loss: 0.0054 - root_mean_squared_error: 0.6563 - val_loss: 0.8977 - val_root_mean_squared_error: 0.9475\n",
      "Epoch 00007: early stopping\n",
      "9\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 15s 283ms/step - loss: 0.0055 - root_mean_squared_error: 0.6406 - val_loss: 0.8913 - val_root_mean_squared_error: 0.9441\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 9s 253ms/step - loss: 0.0050 - root_mean_squared_error: 0.6287 - val_loss: 0.9109 - val_root_mean_squared_error: 0.9544\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 9s 255ms/step - loss: 0.0059 - root_mean_squared_error: 0.6284 - val_loss: 0.9577 - val_root_mean_squared_error: 0.9786\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 10s 261ms/step - loss: 0.0044 - root_mean_squared_error: 0.5970 - val_loss: 0.9225 - val_root_mean_squared_error: 0.9605\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 10s 261ms/step - loss: 0.0051 - root_mean_squared_error: 0.6221 - val_loss: 0.9310 - val_root_mean_squared_error: 0.9649\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0053 - root_mean_squared_error: 0.6135Restoring model weights from the end of the best epoch: 1.\n",
      "37/37 [==============================] - 10s 266ms/step - loss: 0.0053 - root_mean_squared_error: 0.6135 - val_loss: 0.9784 - val_root_mean_squared_error: 0.9891\n",
      "Epoch 00006: early stopping\n",
      "10\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 276ms/step - loss: 0.0052 - root_mean_squared_error: 0.6176 - val_loss: 0.9038 - val_root_mean_squared_error: 0.9507\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 9s 255ms/step - loss: 0.0058 - root_mean_squared_error: 0.6244 - val_loss: 0.9312 - val_root_mean_squared_error: 0.9650\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 10s 259ms/step - loss: 0.0047 - root_mean_squared_error: 0.6020 - val_loss: 0.9231 - val_root_mean_squared_error: 0.9608\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 9s 253ms/step - loss: 0.0055 - root_mean_squared_error: 0.6102 - val_loss: 0.9229 - val_root_mean_squared_error: 0.9607\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 9s 250ms/step - loss: 0.0056 - root_mean_squared_error: 0.6260 - val_loss: 0.9976 - val_root_mean_squared_error: 0.9988\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0053 - root_mean_squared_error: 0.6274Restoring model weights from the end of the best epoch: 1.\n",
      "37/37 [==============================] - 9s 255ms/step - loss: 0.0053 - root_mean_squared_error: 0.6274 - val_loss: 0.9056 - val_root_mean_squared_error: 0.9516\n",
      "Epoch 00006: early stopping\n",
      "11\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 268ms/step - loss: 0.0054 - root_mean_squared_error: 0.6541 - val_loss: 0.8912 - val_root_mean_squared_error: 0.9441\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 9s 251ms/step - loss: 0.0053 - root_mean_squared_error: 0.6328 - val_loss: 0.9068 - val_root_mean_squared_error: 0.9523\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 9s 252ms/step - loss: 0.0061 - root_mean_squared_error: 0.6462 - val_loss: 0.9132 - val_root_mean_squared_error: 0.9556\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 9s 249ms/step - loss: 0.0053 - root_mean_squared_error: 0.6022 - val_loss: 0.9440 - val_root_mean_squared_error: 0.9716\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 10s 260ms/step - loss: 0.0060 - root_mean_squared_error: 0.6479 - val_loss: 0.9517 - val_root_mean_squared_error: 0.9756\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0049 - root_mean_squared_error: 0.6191Restoring model weights from the end of the best epoch: 1.\n",
      "37/37 [==============================] - 9s 256ms/step - loss: 0.0049 - root_mean_squared_error: 0.6191 - val_loss: 0.9792 - val_root_mean_squared_error: 0.9895\n",
      "Epoch 00006: early stopping\n",
      "12\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 273ms/step - loss: 0.0047 - root_mean_squared_error: 0.6030 - val_loss: 0.9112 - val_root_mean_squared_error: 0.9546\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 10s 259ms/step - loss: 0.0051 - root_mean_squared_error: 0.6145 - val_loss: 0.9476 - val_root_mean_squared_error: 0.9734\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 10s 263ms/step - loss: 0.0060 - root_mean_squared_error: 0.6399 - val_loss: 1.0235 - val_root_mean_squared_error: 1.0117\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 10s 264ms/step - loss: 0.0057 - root_mean_squared_error: 0.6367 - val_loss: 1.0607 - val_root_mean_squared_error: 1.0299\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 9s 256ms/step - loss: 0.0052 - root_mean_squared_error: 0.6329 - val_loss: 0.9514 - val_root_mean_squared_error: 0.9754\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0054 - root_mean_squared_error: 0.6143Restoring model weights from the end of the best epoch: 1.\n",
      "37/37 [==============================] - 10s 263ms/step - loss: 0.0054 - root_mean_squared_error: 0.6143 - val_loss: 0.9841 - val_root_mean_squared_error: 0.9920\n",
      "Epoch 00006: early stopping\n",
      "13\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 278ms/step - loss: 0.0055 - root_mean_squared_error: 0.6338 - val_loss: 0.9379 - val_root_mean_squared_error: 0.9684\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 9s 256ms/step - loss: 0.0057 - root_mean_squared_error: 0.6518 - val_loss: 1.0120 - val_root_mean_squared_error: 1.0060\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 10s 261ms/step - loss: 0.0051 - root_mean_squared_error: 0.6309 - val_loss: 0.9316 - val_root_mean_squared_error: 0.9652\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 10s 262ms/step - loss: 0.0049 - root_mean_squared_error: 0.6136 - val_loss: 0.9335 - val_root_mean_squared_error: 0.9662\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 10s 261ms/step - loss: 0.0051 - root_mean_squared_error: 0.6061 - val_loss: 0.9144 - val_root_mean_squared_error: 0.9562\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 10s 265ms/step - loss: 0.0056 - root_mean_squared_error: 0.6304 - val_loss: 0.8719 - val_root_mean_squared_error: 0.9337\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 9s 257ms/step - loss: 0.0050 - root_mean_squared_error: 0.6060 - val_loss: 0.8895 - val_root_mean_squared_error: 0.9431\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 9s 249ms/step - loss: 0.0045 - root_mean_squared_error: 0.6092 - val_loss: 0.9095 - val_root_mean_squared_error: 0.9537\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - 10s 258ms/step - loss: 0.0049 - root_mean_squared_error: 0.6181 - val_loss: 0.9277 - val_root_mean_squared_error: 0.9632\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - 10s 262ms/step - loss: 0.0063 - root_mean_squared_error: 0.6229 - val_loss: 0.9558 - val_root_mean_squared_error: 0.9777\n",
      "Epoch 11/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0047 - root_mean_squared_error: 0.6073Restoring model weights from the end of the best epoch: 6.\n",
      "37/37 [==============================] - 10s 259ms/step - loss: 0.0047 - root_mean_squared_error: 0.6073 - val_loss: 0.9926 - val_root_mean_squared_error: 0.9963\n",
      "Epoch 00011: early stopping\n",
      "14\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 284ms/step - loss: 0.0058 - root_mean_squared_error: 0.6217 - val_loss: 0.9068 - val_root_mean_squared_error: 0.9523\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 10s 263ms/step - loss: 0.0052 - root_mean_squared_error: 0.6347 - val_loss: 0.9727 - val_root_mean_squared_error: 0.9863\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 10s 268ms/step - loss: 0.0058 - root_mean_squared_error: 0.6309 - val_loss: 0.9286 - val_root_mean_squared_error: 0.9636\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 10s 268ms/step - loss: 0.0060 - root_mean_squared_error: 0.6285 - val_loss: 0.8815 - val_root_mean_squared_error: 0.9389\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 10s 263ms/step - loss: 0.0054 - root_mean_squared_error: 0.6245 - val_loss: 0.9237 - val_root_mean_squared_error: 0.9611\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 10s 261ms/step - loss: 0.0051 - root_mean_squared_error: 0.6191 - val_loss: 0.8738 - val_root_mean_squared_error: 0.9348\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 10s 267ms/step - loss: 0.0040 - root_mean_squared_error: 0.5913 - val_loss: 0.9030 - val_root_mean_squared_error: 0.9503\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 10s 265ms/step - loss: 0.0050 - root_mean_squared_error: 0.6224 - val_loss: 0.9175 - val_root_mean_squared_error: 0.9579\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - 10s 263ms/step - loss: 0.0047 - root_mean_squared_error: 0.6151 - val_loss: 0.9245 - val_root_mean_squared_error: 0.9615\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - 10s 259ms/step - loss: 0.0058 - root_mean_squared_error: 0.6135 - val_loss: 0.9531 - val_root_mean_squared_error: 0.9763\n",
      "Epoch 11/1000\n",
      "37/37 [==============================] - 10s 265ms/step - loss: 0.0065 - root_mean_squared_error: 0.6463 - val_loss: 0.8684 - val_root_mean_squared_error: 0.9319\n",
      "Epoch 12/1000\n",
      "37/37 [==============================] - 10s 258ms/step - loss: 0.0047 - root_mean_squared_error: 0.6061 - val_loss: 0.8945 - val_root_mean_squared_error: 0.9458\n",
      "Epoch 13/1000\n",
      "37/37 [==============================] - 10s 265ms/step - loss: 0.0046 - root_mean_squared_error: 0.6218 - val_loss: 0.8494 - val_root_mean_squared_error: 0.9216\n",
      "Epoch 14/1000\n",
      "37/37 [==============================] - 9s 254ms/step - loss: 0.0054 - root_mean_squared_error: 0.6304 - val_loss: 0.8780 - val_root_mean_squared_error: 0.9370\n",
      "Epoch 15/1000\n",
      "37/37 [==============================] - 9s 251ms/step - loss: 0.0049 - root_mean_squared_error: 0.6216 - val_loss: 0.9101 - val_root_mean_squared_error: 0.9540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/1000\n",
      "37/37 [==============================] - 9s 237ms/step - loss: 0.0047 - root_mean_squared_error: 0.6128 - val_loss: 0.8956 - val_root_mean_squared_error: 0.9464\n",
      "Epoch 17/1000\n",
      "37/37 [==============================] - 10s 260ms/step - loss: 0.0045 - root_mean_squared_error: 0.5739 - val_loss: 0.8980 - val_root_mean_squared_error: 0.9476\n",
      "Epoch 18/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0059 - root_mean_squared_error: 0.6323Restoring model weights from the end of the best epoch: 13.\n",
      "37/37 [==============================] - 10s 258ms/step - loss: 0.0059 - root_mean_squared_error: 0.6323 - val_loss: 0.9044 - val_root_mean_squared_error: 0.9510\n",
      "Epoch 00018: early stopping\n",
      "15\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 264ms/step - loss: 0.0054 - root_mean_squared_error: 0.6579 - val_loss: 0.8963 - val_root_mean_squared_error: 0.9467\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 9s 250ms/step - loss: 0.0055 - root_mean_squared_error: 0.6220 - val_loss: 0.9522 - val_root_mean_squared_error: 0.9758\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 9s 250ms/step - loss: 0.0056 - root_mean_squared_error: 0.6181 - val_loss: 0.9308 - val_root_mean_squared_error: 0.9648\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 9s 249ms/step - loss: 0.0071 - root_mean_squared_error: 0.6561 - val_loss: 0.9530 - val_root_mean_squared_error: 0.9762\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 9s 249ms/step - loss: 0.0052 - root_mean_squared_error: 0.6600 - val_loss: 0.9751 - val_root_mean_squared_error: 0.9875\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0052 - root_mean_squared_error: 0.6206Restoring model weights from the end of the best epoch: 1.\n",
      "37/37 [==============================] - 9s 255ms/step - loss: 0.0052 - root_mean_squared_error: 0.6206 - val_loss: 0.9375 - val_root_mean_squared_error: 0.9682\n",
      "Epoch 00006: early stopping\n",
      "16\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 283ms/step - loss: 0.0049 - root_mean_squared_error: 0.6264 - val_loss: 0.9459 - val_root_mean_squared_error: 0.9726\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 9s 253ms/step - loss: 0.0050 - root_mean_squared_error: 0.6163 - val_loss: 0.9662 - val_root_mean_squared_error: 0.9829\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 9s 256ms/step - loss: 0.0041 - root_mean_squared_error: 0.5969 - val_loss: 0.9507 - val_root_mean_squared_error: 0.9751\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 10s 266ms/step - loss: 0.0052 - root_mean_squared_error: 0.6219 - val_loss: 0.9339 - val_root_mean_squared_error: 0.9664\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 10s 264ms/step - loss: 0.0054 - root_mean_squared_error: 0.6070 - val_loss: 0.9322 - val_root_mean_squared_error: 0.9655\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 9s 257ms/step - loss: 0.0058 - root_mean_squared_error: 0.6042 - val_loss: 0.9518 - val_root_mean_squared_error: 0.9756\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 9s 254ms/step - loss: 0.0053 - root_mean_squared_error: 0.6295 - val_loss: 0.9728 - val_root_mean_squared_error: 0.9863\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 10s 265ms/step - loss: 0.0049 - root_mean_squared_error: 0.6244 - val_loss: 0.9148 - val_root_mean_squared_error: 0.9564\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - 10s 269ms/step - loss: 0.0050 - root_mean_squared_error: 0.6168 - val_loss: 0.8915 - val_root_mean_squared_error: 0.9442\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - 9s 255ms/step - loss: 0.0046 - root_mean_squared_error: 0.6058 - val_loss: 0.9576 - val_root_mean_squared_error: 0.9786\n",
      "Epoch 11/1000\n",
      "37/37 [==============================] - 10s 263ms/step - loss: 0.0048 - root_mean_squared_error: 0.6184 - val_loss: 0.8708 - val_root_mean_squared_error: 0.9331\n",
      "Epoch 12/1000\n",
      "37/37 [==============================] - 9s 257ms/step - loss: 0.0050 - root_mean_squared_error: 0.6327 - val_loss: 0.9063 - val_root_mean_squared_error: 0.9520\n",
      "Epoch 13/1000\n",
      "37/37 [==============================] - 9s 257ms/step - loss: 0.0050 - root_mean_squared_error: 0.6074 - val_loss: 0.9049 - val_root_mean_squared_error: 0.9513\n",
      "Epoch 14/1000\n",
      "37/37 [==============================] - 10s 264ms/step - loss: 0.0041 - root_mean_squared_error: 0.5914 - val_loss: 0.8956 - val_root_mean_squared_error: 0.9464\n",
      "Epoch 15/1000\n",
      "37/37 [==============================] - 10s 264ms/step - loss: 0.0046 - root_mean_squared_error: 0.6136 - val_loss: 0.9086 - val_root_mean_squared_error: 0.9532\n",
      "Epoch 16/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0050 - root_mean_squared_error: 0.5973Restoring model weights from the end of the best epoch: 11.\n",
      "37/37 [==============================] - 9s 257ms/step - loss: 0.0050 - root_mean_squared_error: 0.5973 - val_loss: 0.9570 - val_root_mean_squared_error: 0.9783\n",
      "Epoch 00016: early stopping\n",
      "17\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 274ms/step - loss: 0.0050 - root_mean_squared_error: 0.6477 - val_loss: 0.8714 - val_root_mean_squared_error: 0.9335\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 9s 255ms/step - loss: 0.0047 - root_mean_squared_error: 0.6141 - val_loss: 0.8942 - val_root_mean_squared_error: 0.9456\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 9s 248ms/step - loss: 0.0050 - root_mean_squared_error: 0.5858 - val_loss: 0.9638 - val_root_mean_squared_error: 0.9817\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 10s 257ms/step - loss: 0.0044 - root_mean_squared_error: 0.5819 - val_loss: 1.0289 - val_root_mean_squared_error: 1.0143\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 10s 260ms/step - loss: 0.0051 - root_mean_squared_error: 0.5924 - val_loss: 0.9342 - val_root_mean_squared_error: 0.9666\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0063 - root_mean_squared_error: 0.6644Restoring model weights from the end of the best epoch: 1.\n",
      "37/37 [==============================] - 10s 263ms/step - loss: 0.0063 - root_mean_squared_error: 0.6644 - val_loss: 0.9610 - val_root_mean_squared_error: 0.9803\n",
      "Epoch 00006: early stopping\n",
      "18\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 270ms/step - loss: 0.0062 - root_mean_squared_error: 0.6371 - val_loss: 0.9373 - val_root_mean_squared_error: 0.9681\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 9s 253ms/step - loss: 0.0056 - root_mean_squared_error: 0.6375 - val_loss: 0.9307 - val_root_mean_squared_error: 0.9647\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 10s 259ms/step - loss: 0.0051 - root_mean_squared_error: 0.6230 - val_loss: 1.0745 - val_root_mean_squared_error: 1.0366\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 10s 258ms/step - loss: 0.0057 - root_mean_squared_error: 0.6189 - val_loss: 0.9332 - val_root_mean_squared_error: 0.9660\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 10s 257ms/step - loss: 0.0054 - root_mean_squared_error: 0.6094 - val_loss: 0.9835 - val_root_mean_squared_error: 0.9917\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 10s 261ms/step - loss: 0.0051 - root_mean_squared_error: 0.6041 - val_loss: 0.9150 - val_root_mean_squared_error: 0.9565\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 9s 253ms/step - loss: 0.0057 - root_mean_squared_error: 0.6309 - val_loss: 0.9136 - val_root_mean_squared_error: 0.9558\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 10s 259ms/step - loss: 0.0054 - root_mean_squared_error: 0.6388 - val_loss: 0.9020 - val_root_mean_squared_error: 0.9498\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - 9s 256ms/step - loss: 0.0051 - root_mean_squared_error: 0.6181 - val_loss: 0.8929 - val_root_mean_squared_error: 0.9450\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - 9s 250ms/step - loss: 0.0059 - root_mean_squared_error: 0.6164 - val_loss: 0.9225 - val_root_mean_squared_error: 0.9605\n",
      "Epoch 11/1000\n",
      "37/37 [==============================] - 9s 247ms/step - loss: 0.0052 - root_mean_squared_error: 0.6197 - val_loss: 0.9657 - val_root_mean_squared_error: 0.9827\n",
      "Epoch 12/1000\n",
      "37/37 [==============================] - 9s 253ms/step - loss: 0.0050 - root_mean_squared_error: 0.6087 - val_loss: 0.9760 - val_root_mean_squared_error: 0.9880\n",
      "Epoch 13/1000\n",
      "37/37 [==============================] - 9s 255ms/step - loss: 0.0056 - root_mean_squared_error: 0.6380 - val_loss: 0.9238 - val_root_mean_squared_error: 0.9611\n",
      "Epoch 14/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0069 - root_mean_squared_error: 0.6486Restoring model weights from the end of the best epoch: 9.\n",
      "37/37 [==============================] - 9s 256ms/step - loss: 0.0069 - root_mean_squared_error: 0.6486 - val_loss: 0.9508 - val_root_mean_squared_error: 0.9751\n",
      "Epoch 00014: early stopping\n",
      "19\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 284ms/step - loss: 0.0052 - root_mean_squared_error: 0.6325 - val_loss: 0.8813 - val_root_mean_squared_error: 0.9388\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 10s 267ms/step - loss: 0.0062 - root_mean_squared_error: 0.5997 - val_loss: 0.9063 - val_root_mean_squared_error: 0.9520\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 10s 261ms/step - loss: 0.0047 - root_mean_squared_error: 0.5839 - val_loss: 0.9147 - val_root_mean_squared_error: 0.9564\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 10s 261ms/step - loss: 0.0058 - root_mean_squared_error: 0.6401 - val_loss: 0.9865 - val_root_mean_squared_error: 0.9932\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 10s 260ms/step - loss: 0.0051 - root_mean_squared_error: 0.6206 - val_loss: 0.9291 - val_root_mean_squared_error: 0.9639\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0050 - root_mean_squared_error: 0.6078Restoring model weights from the end of the best epoch: 1.\n",
      "37/37 [==============================] - 10s 262ms/step - loss: 0.0050 - root_mean_squared_error: 0.6078 - val_loss: 0.9247 - val_root_mean_squared_error: 0.9616\n",
      "Epoch 00006: early stopping\n",
      "20\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 276ms/step - loss: 0.0058 - root_mean_squared_error: 0.6558 - val_loss: 0.9138 - val_root_mean_squared_error: 0.9559\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 10s 266ms/step - loss: 0.0059 - root_mean_squared_error: 0.6160 - val_loss: 0.8997 - val_root_mean_squared_error: 0.9485\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 10s 257ms/step - loss: 0.0045 - root_mean_squared_error: 0.6010 - val_loss: 0.9139 - val_root_mean_squared_error: 0.9560\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 10s 262ms/step - loss: 0.0049 - root_mean_squared_error: 0.6290 - val_loss: 0.9350 - val_root_mean_squared_error: 0.9670\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 10s 266ms/step - loss: 0.0059 - root_mean_squared_error: 0.6344 - val_loss: 0.9283 - val_root_mean_squared_error: 0.9635\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 10s 262ms/step - loss: 0.0046 - root_mean_squared_error: 0.6259 - val_loss: 0.9139 - val_root_mean_squared_error: 0.9560\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0057 - root_mean_squared_error: 0.6643Restoring model weights from the end of the best epoch: 2.\n",
      "37/37 [==============================] - 10s 258ms/step - loss: 0.0057 - root_mean_squared_error: 0.6643 - val_loss: 0.9378 - val_root_mean_squared_error: 0.9684\n",
      "Epoch 00007: early stopping\n",
      "21\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 270ms/step - loss: 0.0047 - root_mean_squared_error: 0.5944 - val_loss: 0.9606 - val_root_mean_squared_error: 0.9801\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 9s 255ms/step - loss: 0.0058 - root_mean_squared_error: 0.6380 - val_loss: 0.9918 - val_root_mean_squared_error: 0.9959\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 9s 252ms/step - loss: 0.0049 - root_mean_squared_error: 0.6240 - val_loss: 0.9068 - val_root_mean_squared_error: 0.9523\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 9s 256ms/step - loss: 0.0046 - root_mean_squared_error: 0.5984 - val_loss: 0.8888 - val_root_mean_squared_error: 0.9428\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 9s 245ms/step - loss: 0.0049 - root_mean_squared_error: 0.6344 - val_loss: 0.8974 - val_root_mean_squared_error: 0.9473\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 9s 245ms/step - loss: 0.0074 - root_mean_squared_error: 0.6272 - val_loss: 0.9501 - val_root_mean_squared_error: 0.9747\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 9s 251ms/step - loss: 0.0051 - root_mean_squared_error: 0.6306 - val_loss: 0.9650 - val_root_mean_squared_error: 0.9823\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 9s 252ms/step - loss: 0.0042 - root_mean_squared_error: 0.5943 - val_loss: 0.9147 - val_root_mean_squared_error: 0.9564\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0048 - root_mean_squared_error: 0.6048Restoring model weights from the end of the best epoch: 4.\n",
      "37/37 [==============================] - 9s 253ms/step - loss: 0.0048 - root_mean_squared_error: 0.6048 - val_loss: 0.9522 - val_root_mean_squared_error: 0.9758\n",
      "Epoch 00009: early stopping\n",
      "22\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 275ms/step - loss: 0.0048 - root_mean_squared_error: 0.6076 - val_loss: 0.9355 - val_root_mean_squared_error: 0.9672\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 10s 259ms/step - loss: 0.0051 - root_mean_squared_error: 0.6211 - val_loss: 0.9405 - val_root_mean_squared_error: 0.9698\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 10s 257ms/step - loss: 0.0052 - root_mean_squared_error: 0.6270 - val_loss: 0.9740 - val_root_mean_squared_error: 0.9869\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 10s 275ms/step - loss: 0.0055 - root_mean_squared_error: 0.6601 - val_loss: 0.9344 - val_root_mean_squared_error: 0.9666\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 10s 261ms/step - loss: 0.0044 - root_mean_squared_error: 0.6026 - val_loss: 0.9466 - val_root_mean_squared_error: 0.9729\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 10s 268ms/step - loss: 0.0053 - root_mean_squared_error: 0.6286 - val_loss: 0.9170 - val_root_mean_squared_error: 0.9576\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 10s 272ms/step - loss: 0.0059 - root_mean_squared_error: 0.6165 - val_loss: 0.8921 - val_root_mean_squared_error: 0.9445\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 10s 258ms/step - loss: 0.0061 - root_mean_squared_error: 0.6231 - val_loss: 0.9375 - val_root_mean_squared_error: 0.9683\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - 10s 258ms/step - loss: 0.0048 - root_mean_squared_error: 0.5983 - val_loss: 0.9751 - val_root_mean_squared_error: 0.9874\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - 10s 260ms/step - loss: 0.0050 - root_mean_squared_error: 0.6206 - val_loss: 0.9693 - val_root_mean_squared_error: 0.9846\n",
      "Epoch 11/1000\n",
      "37/37 [==============================] - 10s 268ms/step - loss: 0.0051 - root_mean_squared_error: 0.5889 - val_loss: 0.9626 - val_root_mean_squared_error: 0.9811\n",
      "Epoch 12/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0051 - root_mean_squared_error: 0.6071Restoring model weights from the end of the best epoch: 7.\n",
      "37/37 [==============================] - 10s 270ms/step - loss: 0.0051 - root_mean_squared_error: 0.6071 - val_loss: 0.9111 - val_root_mean_squared_error: 0.9545\n",
      "Epoch 00012: early stopping\n",
      "23\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 17s 290ms/step - loss: 0.0060 - root_mean_squared_error: 0.6470 - val_loss: 0.9589 - val_root_mean_squared_error: 0.9792\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 10s 264ms/step - loss: 0.0048 - root_mean_squared_error: 0.6107 - val_loss: 0.9152 - val_root_mean_squared_error: 0.9566\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 10s 276ms/step - loss: 0.0046 - root_mean_squared_error: 0.6060 - val_loss: 0.9196 - val_root_mean_squared_error: 0.9590\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 10s 268ms/step - loss: 0.0050 - root_mean_squared_error: 0.6009 - val_loss: 0.9477 - val_root_mean_squared_error: 0.9735\n",
      "Epoch 5/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 10s 268ms/step - loss: 0.0056 - root_mean_squared_error: 0.6401 - val_loss: 0.8982 - val_root_mean_squared_error: 0.9477\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 10s 265ms/step - loss: 0.0046 - root_mean_squared_error: 0.5921 - val_loss: 0.9620 - val_root_mean_squared_error: 0.9808\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 10s 267ms/step - loss: 0.0052 - root_mean_squared_error: 0.6263 - val_loss: 0.9379 - val_root_mean_squared_error: 0.9685\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 10s 261ms/step - loss: 0.0055 - root_mean_squared_error: 0.6339 - val_loss: 0.9891 - val_root_mean_squared_error: 0.9945\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - 9s 253ms/step - loss: 0.0058 - root_mean_squared_error: 0.6431 - val_loss: 0.9834 - val_root_mean_squared_error: 0.9917\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0048 - root_mean_squared_error: 0.6062Restoring model weights from the end of the best epoch: 5.\n",
      "37/37 [==============================] - 9s 255ms/step - loss: 0.0048 - root_mean_squared_error: 0.6062 - val_loss: 0.9126 - val_root_mean_squared_error: 0.9553\n",
      "Epoch 00010: early stopping\n",
      "24\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 272ms/step - loss: 0.0050 - root_mean_squared_error: 0.6244 - val_loss: 0.9499 - val_root_mean_squared_error: 0.9746\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 10s 261ms/step - loss: 0.0055 - root_mean_squared_error: 0.6315 - val_loss: 0.9368 - val_root_mean_squared_error: 0.9679\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 10s 266ms/step - loss: 0.0046 - root_mean_squared_error: 0.6075 - val_loss: 0.9442 - val_root_mean_squared_error: 0.9717\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 10s 262ms/step - loss: 0.0059 - root_mean_squared_error: 0.6313 - val_loss: 0.9157 - val_root_mean_squared_error: 0.9569\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 10s 260ms/step - loss: 0.0045 - root_mean_squared_error: 0.6036 - val_loss: 0.9402 - val_root_mean_squared_error: 0.9696\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 10s 271ms/step - loss: 0.0048 - root_mean_squared_error: 0.6066 - val_loss: 0.8814 - val_root_mean_squared_error: 0.9388\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 10s 262ms/step - loss: 0.0053 - root_mean_squared_error: 0.6022 - val_loss: 0.8697 - val_root_mean_squared_error: 0.9326\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 9s 257ms/step - loss: 0.0063 - root_mean_squared_error: 0.6496 - val_loss: 0.8813 - val_root_mean_squared_error: 0.9388\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - 10s 268ms/step - loss: 0.0051 - root_mean_squared_error: 0.6268 - val_loss: 0.8554 - val_root_mean_squared_error: 0.9249\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - 9s 254ms/step - loss: 0.0061 - root_mean_squared_error: 0.6214 - val_loss: 0.8777 - val_root_mean_squared_error: 0.9369\n",
      "Epoch 11/1000\n",
      "37/37 [==============================] - 9s 255ms/step - loss: 0.0049 - root_mean_squared_error: 0.6123 - val_loss: 0.9592 - val_root_mean_squared_error: 0.9794\n",
      "Epoch 12/1000\n",
      "37/37 [==============================] - 9s 254ms/step - loss: 0.0054 - root_mean_squared_error: 0.6162 - val_loss: 0.8913 - val_root_mean_squared_error: 0.9441\n",
      "Epoch 13/1000\n",
      "37/37 [==============================] - 9s 257ms/step - loss: 0.0058 - root_mean_squared_error: 0.6441 - val_loss: 0.9188 - val_root_mean_squared_error: 0.9585\n",
      "Epoch 14/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0044 - root_mean_squared_error: 0.5817Restoring model weights from the end of the best epoch: 9.\n",
      "37/37 [==============================] - 10s 260ms/step - loss: 0.0044 - root_mean_squared_error: 0.5817 - val_loss: 0.8680 - val_root_mean_squared_error: 0.9317\n",
      "Epoch 00014: early stopping\n",
      "25\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 268ms/step - loss: 0.0065 - root_mean_squared_error: 0.6624 - val_loss: 0.9038 - val_root_mean_squared_error: 0.9507\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 10s 263ms/step - loss: 0.0068 - root_mean_squared_error: 0.6630 - val_loss: 0.9001 - val_root_mean_squared_error: 0.9487\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 10s 261ms/step - loss: 0.0051 - root_mean_squared_error: 0.6168 - val_loss: 0.9674 - val_root_mean_squared_error: 0.9836\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 10s 257ms/step - loss: 0.0050 - root_mean_squared_error: 0.6207 - val_loss: 0.9577 - val_root_mean_squared_error: 0.9786\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 10s 259ms/step - loss: 0.0057 - root_mean_squared_error: 0.6489 - val_loss: 0.9066 - val_root_mean_squared_error: 0.9522\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 10s 259ms/step - loss: 0.0051 - root_mean_squared_error: 0.6006 - val_loss: 0.9037 - val_root_mean_squared_error: 0.9507\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0049 - root_mean_squared_error: 0.6164Restoring model weights from the end of the best epoch: 2.\n",
      "37/37 [==============================] - 9s 257ms/step - loss: 0.0049 - root_mean_squared_error: 0.6164 - val_loss: 0.9206 - val_root_mean_squared_error: 0.9595\n",
      "Epoch 00007: early stopping\n",
      "26\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 279ms/step - loss: 0.0052 - root_mean_squared_error: 0.6298 - val_loss: 0.9523 - val_root_mean_squared_error: 0.9759\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 10s 265ms/step - loss: 0.0046 - root_mean_squared_error: 0.6105 - val_loss: 0.8959 - val_root_mean_squared_error: 0.9465\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 10s 261ms/step - loss: 0.0058 - root_mean_squared_error: 0.6300 - val_loss: 0.8954 - val_root_mean_squared_error: 0.9463\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 10s 257ms/step - loss: 0.0061 - root_mean_squared_error: 0.6550 - val_loss: 0.9787 - val_root_mean_squared_error: 0.9893\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 9s 248ms/step - loss: 0.0049 - root_mean_squared_error: 0.6096 - val_loss: 0.9148 - val_root_mean_squared_error: 0.9565\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 10s 261ms/step - loss: 0.0056 - root_mean_squared_error: 0.6182 - val_loss: 0.8700 - val_root_mean_squared_error: 0.9328\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 9s 257ms/step - loss: 0.0058 - root_mean_squared_error: 0.6301 - val_loss: 0.9202 - val_root_mean_squared_error: 0.9593\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 10s 265ms/step - loss: 0.0064 - root_mean_squared_error: 0.6286 - val_loss: 0.9717 - val_root_mean_squared_error: 0.9857\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - 10s 262ms/step - loss: 0.0052 - root_mean_squared_error: 0.6328 - val_loss: 0.9034 - val_root_mean_squared_error: 0.9505\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - 10s 262ms/step - loss: 0.0048 - root_mean_squared_error: 0.6021 - val_loss: 0.9646 - val_root_mean_squared_error: 0.9821\n",
      "Epoch 11/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0055 - root_mean_squared_error: 0.6302Restoring model weights from the end of the best epoch: 6.\n",
      "37/37 [==============================] - 10s 266ms/step - loss: 0.0055 - root_mean_squared_error: 0.6302 - val_loss: 0.9294 - val_root_mean_squared_error: 0.9640\n",
      "Epoch 00011: early stopping\n",
      "27\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 15s 290ms/step - loss: 0.0063 - root_mean_squared_error: 0.6190 - val_loss: 0.9432 - val_root_mean_squared_error: 0.9712\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 10s 267ms/step - loss: 0.0062 - root_mean_squared_error: 0.6172 - val_loss: 0.9594 - val_root_mean_squared_error: 0.9795\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 10s 269ms/step - loss: 0.0057 - root_mean_squared_error: 0.6306 - val_loss: 0.9409 - val_root_mean_squared_error: 0.9700\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 10s 275ms/step - loss: 0.0056 - root_mean_squared_error: 0.6501 - val_loss: 0.9272 - val_root_mean_squared_error: 0.9629\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 10s 271ms/step - loss: 0.0051 - root_mean_squared_error: 0.6207 - val_loss: 0.9239 - val_root_mean_squared_error: 0.9612\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 10s 265ms/step - loss: 0.0046 - root_mean_squared_error: 0.6180 - val_loss: 0.9154 - val_root_mean_squared_error: 0.9568\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 10s 267ms/step - loss: 0.0058 - root_mean_squared_error: 0.6178 - val_loss: 0.9394 - val_root_mean_squared_error: 0.9693\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 10s 269ms/step - loss: 0.0049 - root_mean_squared_error: 0.6101 - val_loss: 0.9587 - val_root_mean_squared_error: 0.9791\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - 10s 267ms/step - loss: 0.0058 - root_mean_squared_error: 0.6269 - val_loss: 0.9471 - val_root_mean_squared_error: 0.9732\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - 10s 263ms/step - loss: 0.0052 - root_mean_squared_error: 0.6006 - val_loss: 0.9153 - val_root_mean_squared_error: 0.9567\n",
      "Epoch 11/1000\n",
      "37/37 [==============================] - 10s 282ms/step - loss: 0.0048 - root_mean_squared_error: 0.6002 - val_loss: 0.8608 - val_root_mean_squared_error: 0.9278\n",
      "Epoch 12/1000\n",
      "37/37 [==============================] - 10s 277ms/step - loss: 0.0047 - root_mean_squared_error: 0.5996 - val_loss: 0.8869 - val_root_mean_squared_error: 0.9417\n",
      "Epoch 13/1000\n",
      "37/37 [==============================] - 10s 277ms/step - loss: 0.0048 - root_mean_squared_error: 0.6019 - val_loss: 0.9015 - val_root_mean_squared_error: 0.9495\n",
      "Epoch 14/1000\n",
      "37/37 [==============================] - 10s 261ms/step - loss: 0.0053 - root_mean_squared_error: 0.6118 - val_loss: 0.9520 - val_root_mean_squared_error: 0.9757\n",
      "Epoch 15/1000\n",
      "37/37 [==============================] - 10s 272ms/step - loss: 0.0047 - root_mean_squared_error: 0.6216 - val_loss: 0.9323 - val_root_mean_squared_error: 0.9656\n",
      "Epoch 16/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0047 - root_mean_squared_error: 0.6100Restoring model weights from the end of the best epoch: 11.\n",
      "37/37 [==============================] - 10s 279ms/step - loss: 0.0047 - root_mean_squared_error: 0.6100 - val_loss: 0.9422 - val_root_mean_squared_error: 0.9707\n",
      "Epoch 00016: early stopping\n",
      "28\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 15s 292ms/step - loss: 0.0054 - root_mean_squared_error: 0.6138 - val_loss: 0.8786 - val_root_mean_squared_error: 0.9373\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 9s 255ms/step - loss: 0.0050 - root_mean_squared_error: 0.6299 - val_loss: 0.8936 - val_root_mean_squared_error: 0.9453\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 9s 256ms/step - loss: 0.0054 - root_mean_squared_error: 0.6062 - val_loss: 0.9230 - val_root_mean_squared_error: 0.9607\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 9s 252ms/step - loss: 0.0051 - root_mean_squared_error: 0.6204 - val_loss: 0.9326 - val_root_mean_squared_error: 0.9657\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 9s 253ms/step - loss: 0.0046 - root_mean_squared_error: 0.5697 - val_loss: 0.9064 - val_root_mean_squared_error: 0.9521\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0048 - root_mean_squared_error: 0.6070Restoring model weights from the end of the best epoch: 1.\n",
      "37/37 [==============================] - 10s 261ms/step - loss: 0.0048 - root_mean_squared_error: 0.6070 - val_loss: 0.9236 - val_root_mean_squared_error: 0.9610\n",
      "Epoch 00006: early stopping\n",
      "29\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 275ms/step - loss: 0.0048 - root_mean_squared_error: 0.6444 - val_loss: 0.8727 - val_root_mean_squared_error: 0.9342\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 9s 254ms/step - loss: 0.0058 - root_mean_squared_error: 0.6212 - val_loss: 0.8925 - val_root_mean_squared_error: 0.9447\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 10s 260ms/step - loss: 0.0047 - root_mean_squared_error: 0.6159 - val_loss: 0.9293 - val_root_mean_squared_error: 0.9640\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 9s 254ms/step - loss: 0.0042 - root_mean_squared_error: 0.5988 - val_loss: 0.8945 - val_root_mean_squared_error: 0.9458\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 9s 256ms/step - loss: 0.0060 - root_mean_squared_error: 0.6342 - val_loss: 0.9347 - val_root_mean_squared_error: 0.9668\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0051 - root_mean_squared_error: 0.6256Restoring model weights from the end of the best epoch: 1.\n",
      "37/37 [==============================] - 9s 252ms/step - loss: 0.0051 - root_mean_squared_error: 0.6256 - val_loss: 0.9431 - val_root_mean_squared_error: 0.9711\n",
      "Epoch 00006: early stopping\n",
      "30\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 276ms/step - loss: 0.0050 - root_mean_squared_error: 0.6394 - val_loss: 0.9210 - val_root_mean_squared_error: 0.9597\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 10s 264ms/step - loss: 0.0061 - root_mean_squared_error: 0.6383 - val_loss: 0.9093 - val_root_mean_squared_error: 0.9536\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 10s 261ms/step - loss: 0.0052 - root_mean_squared_error: 0.6298 - val_loss: 0.8717 - val_root_mean_squared_error: 0.9337\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 9s 254ms/step - loss: 0.0059 - root_mean_squared_error: 0.6471 - val_loss: 0.9410 - val_root_mean_squared_error: 0.9700\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 10s 270ms/step - loss: 0.0048 - root_mean_squared_error: 0.6225 - val_loss: 0.8857 - val_root_mean_squared_error: 0.9411\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 10s 268ms/step - loss: 0.0050 - root_mean_squared_error: 0.6089 - val_loss: 0.9167 - val_root_mean_squared_error: 0.9574\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 10s 270ms/step - loss: 0.0054 - root_mean_squared_error: 0.6262 - val_loss: 0.9211 - val_root_mean_squared_error: 0.9598\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0051 - root_mean_squared_error: 0.6421Restoring model weights from the end of the best epoch: 3.\n",
      "37/37 [==============================] - 9s 254ms/step - loss: 0.0051 - root_mean_squared_error: 0.6421 - val_loss: 0.9144 - val_root_mean_squared_error: 0.9562\n",
      "Epoch 00008: early stopping\n",
      "31\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 264ms/step - loss: 0.0047 - root_mean_squared_error: 0.6022 - val_loss: 0.8925 - val_root_mean_squared_error: 0.9447\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 9s 247ms/step - loss: 0.0055 - root_mean_squared_error: 0.6186 - val_loss: 0.8957 - val_root_mean_squared_error: 0.9464\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 9s 238ms/step - loss: 0.0050 - root_mean_squared_error: 0.6092 - val_loss: 0.9347 - val_root_mean_squared_error: 0.9668\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 9s 244ms/step - loss: 0.0048 - root_mean_squared_error: 0.6256 - val_loss: 0.9536 - val_root_mean_squared_error: 0.9765\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 9s 243ms/step - loss: 0.0062 - root_mean_squared_error: 0.6460 - val_loss: 0.8971 - val_root_mean_squared_error: 0.9472\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0052 - root_mean_squared_error: 0.6262Restoring model weights from the end of the best epoch: 1.\n",
      "37/37 [==============================] - 9s 247ms/step - loss: 0.0052 - root_mean_squared_error: 0.6262 - val_loss: 0.9025 - val_root_mean_squared_error: 0.9500\n",
      "Epoch 00006: early stopping\n",
      "32\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 268ms/step - loss: 0.0051 - root_mean_squared_error: 0.6428 - val_loss: 0.9096 - val_root_mean_squared_error: 0.9538\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 9s 247ms/step - loss: 0.0051 - root_mean_squared_error: 0.6515 - val_loss: 0.9233 - val_root_mean_squared_error: 0.9609\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 9s 247ms/step - loss: 0.0047 - root_mean_squared_error: 0.6257 - val_loss: 0.9609 - val_root_mean_squared_error: 0.9803\n",
      "Epoch 4/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 9s 250ms/step - loss: 0.0059 - root_mean_squared_error: 0.6339 - val_loss: 0.9486 - val_root_mean_squared_error: 0.9740\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 9s 237ms/step - loss: 0.0052 - root_mean_squared_error: 0.6260 - val_loss: 0.9117 - val_root_mean_squared_error: 0.9548\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0043 - root_mean_squared_error: 0.5920Restoring model weights from the end of the best epoch: 1.\n",
      "37/37 [==============================] - 9s 247ms/step - loss: 0.0043 - root_mean_squared_error: 0.5920 - val_loss: 0.9421 - val_root_mean_squared_error: 0.9706\n",
      "Epoch 00006: early stopping\n",
      "33\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 15s 286ms/step - loss: 0.0055 - root_mean_squared_error: 0.6237 - val_loss: 0.8977 - val_root_mean_squared_error: 0.9475\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 10s 270ms/step - loss: 0.0045 - root_mean_squared_error: 0.5886 - val_loss: 0.8761 - val_root_mean_squared_error: 0.9360\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 9s 256ms/step - loss: 0.0053 - root_mean_squared_error: 0.6216 - val_loss: 0.8682 - val_root_mean_squared_error: 0.9318\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 9s 253ms/step - loss: 0.0047 - root_mean_squared_error: 0.6015 - val_loss: 0.8642 - val_root_mean_squared_error: 0.9296\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 9s 257ms/step - loss: 0.0043 - root_mean_squared_error: 0.6041 - val_loss: 0.8630 - val_root_mean_squared_error: 0.9290\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 9s 254ms/step - loss: 0.0052 - root_mean_squared_error: 0.6259 - val_loss: 0.8993 - val_root_mean_squared_error: 0.9483\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 10s 261ms/step - loss: 0.0061 - root_mean_squared_error: 0.6188 - val_loss: 0.9800 - val_root_mean_squared_error: 0.9899\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 9s 256ms/step - loss: 0.0048 - root_mean_squared_error: 0.6186 - val_loss: 0.9031 - val_root_mean_squared_error: 0.9503\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - 9s 256ms/step - loss: 0.0046 - root_mean_squared_error: 0.6015 - val_loss: 0.8942 - val_root_mean_squared_error: 0.9456\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0055 - root_mean_squared_error: 0.6171Restoring model weights from the end of the best epoch: 5.\n",
      "37/37 [==============================] - 10s 266ms/step - loss: 0.0055 - root_mean_squared_error: 0.6171 - val_loss: 0.8775 - val_root_mean_squared_error: 0.9367\n",
      "Epoch 00010: early stopping\n",
      "34\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 282ms/step - loss: 0.0047 - root_mean_squared_error: 0.6124 - val_loss: 0.8915 - val_root_mean_squared_error: 0.9442\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 9s 256ms/step - loss: 0.0054 - root_mean_squared_error: 0.6337 - val_loss: 0.9502 - val_root_mean_squared_error: 0.9748\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 10s 257ms/step - loss: 0.0055 - root_mean_squared_error: 0.6440 - val_loss: 0.9230 - val_root_mean_squared_error: 0.9607\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 9s 257ms/step - loss: 0.0058 - root_mean_squared_error: 0.6346 - val_loss: 0.9286 - val_root_mean_squared_error: 0.9636\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 10s 258ms/step - loss: 0.0050 - root_mean_squared_error: 0.6052 - val_loss: 0.9089 - val_root_mean_squared_error: 0.9533\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0054 - root_mean_squared_error: 0.6096Restoring model weights from the end of the best epoch: 1.\n",
      "37/37 [==============================] - 10s 258ms/step - loss: 0.0054 - root_mean_squared_error: 0.6096 - val_loss: 0.9283 - val_root_mean_squared_error: 0.9635\n",
      "Epoch 00006: early stopping\n",
      "35\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 274ms/step - loss: 0.0056 - root_mean_squared_error: 0.6156 - val_loss: 0.9162 - val_root_mean_squared_error: 0.9572\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 10s 260ms/step - loss: 0.0047 - root_mean_squared_error: 0.6265 - val_loss: 0.9015 - val_root_mean_squared_error: 0.9495\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 9s 253ms/step - loss: 0.0051 - root_mean_squared_error: 0.6388 - val_loss: 0.9417 - val_root_mean_squared_error: 0.9704\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 9s 252ms/step - loss: 0.0051 - root_mean_squared_error: 0.5938 - val_loss: 0.9562 - val_root_mean_squared_error: 0.9779\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 9s 250ms/step - loss: 0.0061 - root_mean_squared_error: 0.6320 - val_loss: 0.9065 - val_root_mean_squared_error: 0.9521\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 9s 246ms/step - loss: 0.0052 - root_mean_squared_error: 0.6195 - val_loss: 0.9370 - val_root_mean_squared_error: 0.9680\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0047 - root_mean_squared_error: 0.5908Restoring model weights from the end of the best epoch: 2.\n",
      "37/37 [==============================] - 9s 257ms/step - loss: 0.0047 - root_mean_squared_error: 0.5908 - val_loss: 0.9435 - val_root_mean_squared_error: 0.9713\n",
      "Epoch 00007: early stopping\n",
      "36\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 283ms/step - loss: 0.0052 - root_mean_squared_error: 0.6211 - val_loss: 0.9709 - val_root_mean_squared_error: 0.9854\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 10s 258ms/step - loss: 0.0052 - root_mean_squared_error: 0.6205 - val_loss: 0.9180 - val_root_mean_squared_error: 0.9581\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 10s 262ms/step - loss: 0.0049 - root_mean_squared_error: 0.6124 - val_loss: 0.9549 - val_root_mean_squared_error: 0.9772\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 9s 257ms/step - loss: 0.0055 - root_mean_squared_error: 0.6137 - val_loss: 0.8779 - val_root_mean_squared_error: 0.9370\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 10s 260ms/step - loss: 0.0058 - root_mean_squared_error: 0.6482 - val_loss: 0.8603 - val_root_mean_squared_error: 0.9275\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 9s 251ms/step - loss: 0.0049 - root_mean_squared_error: 0.6170 - val_loss: 0.8647 - val_root_mean_squared_error: 0.9299\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 9s 252ms/step - loss: 0.0052 - root_mean_squared_error: 0.5910 - val_loss: 0.8858 - val_root_mean_squared_error: 0.9411\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 9s 253ms/step - loss: 0.0055 - root_mean_squared_error: 0.6092 - val_loss: 0.9517 - val_root_mean_squared_error: 0.9755\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - 9s 256ms/step - loss: 0.0051 - root_mean_squared_error: 0.6266 - val_loss: 0.9105 - val_root_mean_squared_error: 0.9542\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0052 - root_mean_squared_error: 0.6140Restoring model weights from the end of the best epoch: 5.\n",
      "37/37 [==============================] - 10s 257ms/step - loss: 0.0052 - root_mean_squared_error: 0.6140 - val_loss: 0.9080 - val_root_mean_squared_error: 0.9529\n",
      "Epoch 00010: early stopping\n",
      "37\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 274ms/step - loss: 0.0052 - root_mean_squared_error: 0.6252 - val_loss: 0.9420 - val_root_mean_squared_error: 0.9706\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 10s 261ms/step - loss: 0.0059 - root_mean_squared_error: 0.6491 - val_loss: 0.9640 - val_root_mean_squared_error: 0.9819\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 10s 265ms/step - loss: 0.0053 - root_mean_squared_error: 0.6209 - val_loss: 0.9203 - val_root_mean_squared_error: 0.9593\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 10s 263ms/step - loss: 0.0051 - root_mean_squared_error: 0.6372 - val_loss: 0.9199 - val_root_mean_squared_error: 0.9591\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 10s 263ms/step - loss: 0.0054 - root_mean_squared_error: 0.6273 - val_loss: 0.9069 - val_root_mean_squared_error: 0.9523\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 10s 264ms/step - loss: 0.0057 - root_mean_squared_error: 0.6357 - val_loss: 0.9058 - val_root_mean_squared_error: 0.9517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/1000\n",
      "37/37 [==============================] - 10s 258ms/step - loss: 0.0056 - root_mean_squared_error: 0.6099 - val_loss: 0.9328 - val_root_mean_squared_error: 0.9658\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 9s 255ms/step - loss: 0.0060 - root_mean_squared_error: 0.6233 - val_loss: 0.9318 - val_root_mean_squared_error: 0.9653\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - 10s 262ms/step - loss: 0.0054 - root_mean_squared_error: 0.6456 - val_loss: 0.9402 - val_root_mean_squared_error: 0.9696\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - 9s 255ms/step - loss: 0.0046 - root_mean_squared_error: 0.6111 - val_loss: 0.9387 - val_root_mean_squared_error: 0.9689\n",
      "Epoch 11/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0044 - root_mean_squared_error: 0.6038Restoring model weights from the end of the best epoch: 6.\n",
      "37/37 [==============================] - 10s 260ms/step - loss: 0.0044 - root_mean_squared_error: 0.6038 - val_loss: 0.9134 - val_root_mean_squared_error: 0.9557\n",
      "Epoch 00011: early stopping\n",
      "38\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 268ms/step - loss: 0.0053 - root_mean_squared_error: 0.6467 - val_loss: 0.9551 - val_root_mean_squared_error: 0.9773\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 9s 250ms/step - loss: 0.0052 - root_mean_squared_error: 0.6215 - val_loss: 0.9914 - val_root_mean_squared_error: 0.9957\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 9s 251ms/step - loss: 0.0050 - root_mean_squared_error: 0.6064 - val_loss: 0.9577 - val_root_mean_squared_error: 0.9786\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 9s 257ms/step - loss: 0.0042 - root_mean_squared_error: 0.6020 - val_loss: 0.8803 - val_root_mean_squared_error: 0.9383\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 10s 259ms/step - loss: 0.0055 - root_mean_squared_error: 0.6389 - val_loss: 0.9123 - val_root_mean_squared_error: 0.9551\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 9s 253ms/step - loss: 0.0048 - root_mean_squared_error: 0.6038 - val_loss: 0.9046 - val_root_mean_squared_error: 0.9511\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 9s 257ms/step - loss: 0.0056 - root_mean_squared_error: 0.6252 - val_loss: 0.9697 - val_root_mean_squared_error: 0.9848\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 9s 256ms/step - loss: 0.0053 - root_mean_squared_error: 0.6177 - val_loss: 0.8905 - val_root_mean_squared_error: 0.9437\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0046 - root_mean_squared_error: 0.6151Restoring model weights from the end of the best epoch: 4.\n",
      "37/37 [==============================] - 10s 273ms/step - loss: 0.0046 - root_mean_squared_error: 0.6151 - val_loss: 0.8943 - val_root_mean_squared_error: 0.9457\n",
      "Epoch 00009: early stopping\n",
      "39\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 281ms/step - loss: 0.0066 - root_mean_squared_error: 0.6283 - val_loss: 0.9147 - val_root_mean_squared_error: 0.9564\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 10s 259ms/step - loss: 0.0052 - root_mean_squared_error: 0.6272 - val_loss: 0.9382 - val_root_mean_squared_error: 0.9686\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 9s 250ms/step - loss: 0.0051 - root_mean_squared_error: 0.6416 - val_loss: 0.9279 - val_root_mean_squared_error: 0.9633\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 9s 255ms/step - loss: 0.0049 - root_mean_squared_error: 0.6187 - val_loss: 0.8925 - val_root_mean_squared_error: 0.9447\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 9s 247ms/step - loss: 0.0063 - root_mean_squared_error: 0.6053 - val_loss: 0.9064 - val_root_mean_squared_error: 0.9520\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 9s 251ms/step - loss: 0.0046 - root_mean_squared_error: 0.6066 - val_loss: 0.8952 - val_root_mean_squared_error: 0.9462\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 9s 249ms/step - loss: 0.0052 - root_mean_squared_error: 0.6131 - val_loss: 0.9305 - val_root_mean_squared_error: 0.9646\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 9s 251ms/step - loss: 0.0047 - root_mean_squared_error: 0.6004 - val_loss: 0.9482 - val_root_mean_squared_error: 0.9738\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0053 - root_mean_squared_error: 0.6125Restoring model weights from the end of the best epoch: 4.\n",
      "37/37 [==============================] - 9s 250ms/step - loss: 0.0053 - root_mean_squared_error: 0.6125 - val_loss: 0.9468 - val_root_mean_squared_error: 0.9731\n",
      "Epoch 00009: early stopping\n",
      "40\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 268ms/step - loss: 0.0055 - root_mean_squared_error: 0.6391 - val_loss: 0.8867 - val_root_mean_squared_error: 0.9416\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 10s 257ms/step - loss: 0.0048 - root_mean_squared_error: 0.6178 - val_loss: 0.9088 - val_root_mean_squared_error: 0.9533\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 9s 248ms/step - loss: 0.0056 - root_mean_squared_error: 0.6392 - val_loss: 0.8919 - val_root_mean_squared_error: 0.9444\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 9s 250ms/step - loss: 0.0059 - root_mean_squared_error: 0.6420 - val_loss: 0.9536 - val_root_mean_squared_error: 0.9765\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 9s 252ms/step - loss: 0.0053 - root_mean_squared_error: 0.6289 - val_loss: 0.9633 - val_root_mean_squared_error: 0.9815\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0049 - root_mean_squared_error: 0.6144Restoring model weights from the end of the best epoch: 1.\n",
      "37/37 [==============================] - 9s 253ms/step - loss: 0.0049 - root_mean_squared_error: 0.6144 - val_loss: 0.9274 - val_root_mean_squared_error: 0.9630\n",
      "Epoch 00006: early stopping\n",
      "41\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 287ms/step - loss: 0.0048 - root_mean_squared_error: 0.6108 - val_loss: 0.9380 - val_root_mean_squared_error: 0.9685\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 10s 268ms/step - loss: 0.0053 - root_mean_squared_error: 0.6195 - val_loss: 0.9577 - val_root_mean_squared_error: 0.9786\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 10s 263ms/step - loss: 0.0057 - root_mean_squared_error: 0.6454 - val_loss: 0.9493 - val_root_mean_squared_error: 0.9743\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 10s 263ms/step - loss: 0.0048 - root_mean_squared_error: 0.6271 - val_loss: 0.9914 - val_root_mean_squared_error: 0.9957\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 10s 261ms/step - loss: 0.0049 - root_mean_squared_error: 0.6272 - val_loss: 1.0264 - val_root_mean_squared_error: 1.0131\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0052 - root_mean_squared_error: 0.6010Restoring model weights from the end of the best epoch: 1.\n",
      "37/37 [==============================] - 10s 265ms/step - loss: 0.0052 - root_mean_squared_error: 0.6010 - val_loss: 0.9396 - val_root_mean_squared_error: 0.9693\n",
      "Epoch 00006: early stopping\n",
      "42\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 275ms/step - loss: 0.0062 - root_mean_squared_error: 0.6497 - val_loss: 0.9382 - val_root_mean_squared_error: 0.9686\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 9s 247ms/step - loss: 0.0053 - root_mean_squared_error: 0.6333 - val_loss: 0.9538 - val_root_mean_squared_error: 0.9766\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 9s 252ms/step - loss: 0.0062 - root_mean_squared_error: 0.6561 - val_loss: 0.9556 - val_root_mean_squared_error: 0.9775\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 9s 253ms/step - loss: 0.0060 - root_mean_squared_error: 0.6396 - val_loss: 0.9394 - val_root_mean_squared_error: 0.9692\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 9s 252ms/step - loss: 0.0057 - root_mean_squared_error: 0.6407 - val_loss: 0.9308 - val_root_mean_squared_error: 0.9648\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 9s 240ms/step - loss: 0.0052 - root_mean_squared_error: 0.6160 - val_loss: 0.9986 - val_root_mean_squared_error: 0.9993\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 9s 253ms/step - loss: 0.0049 - root_mean_squared_error: 0.6038 - val_loss: 0.9152 - val_root_mean_squared_error: 0.9567\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 10s 263ms/step - loss: 0.0050 - root_mean_squared_error: 0.6057 - val_loss: 0.8831 - val_root_mean_squared_error: 0.9397\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - 9s 252ms/step - loss: 0.0050 - root_mean_squared_error: 0.6194 - val_loss: 0.9527 - val_root_mean_squared_error: 0.9761\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - 9s 253ms/step - loss: 0.0051 - root_mean_squared_error: 0.6438 - val_loss: 0.9410 - val_root_mean_squared_error: 0.9700\n",
      "Epoch 11/1000\n",
      "37/37 [==============================] - 9s 251ms/step - loss: 0.0048 - root_mean_squared_error: 0.6174 - val_loss: 0.9348 - val_root_mean_squared_error: 0.9668\n",
      "Epoch 12/1000\n",
      "37/37 [==============================] - 9s 250ms/step - loss: 0.0047 - root_mean_squared_error: 0.6062 - val_loss: 0.8850 - val_root_mean_squared_error: 0.9407\n",
      "Epoch 13/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0049 - root_mean_squared_error: 0.6357Restoring model weights from the end of the best epoch: 8.\n",
      "37/37 [==============================] - 10s 260ms/step - loss: 0.0049 - root_mean_squared_error: 0.6357 - val_loss: 0.9301 - val_root_mean_squared_error: 0.9644\n",
      "Epoch 00013: early stopping\n",
      "43\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 15s 279ms/step - loss: 0.0048 - root_mean_squared_error: 0.5962 - val_loss: 0.8816 - val_root_mean_squared_error: 0.9389\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 10s 262ms/step - loss: 0.0064 - root_mean_squared_error: 0.6078 - val_loss: 0.8730 - val_root_mean_squared_error: 0.9344\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 10s 264ms/step - loss: 0.0049 - root_mean_squared_error: 0.6212 - val_loss: 0.8946 - val_root_mean_squared_error: 0.9458\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 10s 262ms/step - loss: 0.0049 - root_mean_squared_error: 0.6067 - val_loss: 0.8891 - val_root_mean_squared_error: 0.9429\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 10s 258ms/step - loss: 0.0060 - root_mean_squared_error: 0.6302 - val_loss: 0.9571 - val_root_mean_squared_error: 0.9783\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 10s 257ms/step - loss: 0.0049 - root_mean_squared_error: 0.5914 - val_loss: 0.9358 - val_root_mean_squared_error: 0.9674\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0049 - root_mean_squared_error: 0.6237Restoring model weights from the end of the best epoch: 2.\n",
      "37/37 [==============================] - 10s 268ms/step - loss: 0.0049 - root_mean_squared_error: 0.6237 - val_loss: 0.9145 - val_root_mean_squared_error: 0.9563\n",
      "Epoch 00007: early stopping\n",
      "44\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 273ms/step - loss: 0.0046 - root_mean_squared_error: 0.6201 - val_loss: 0.8656 - val_root_mean_squared_error: 0.9304\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 9s 256ms/step - loss: 0.0060 - root_mean_squared_error: 0.6397 - val_loss: 0.9069 - val_root_mean_squared_error: 0.9523\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 9s 246ms/step - loss: 0.0047 - root_mean_squared_error: 0.6255 - val_loss: 0.9025 - val_root_mean_squared_error: 0.9500\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 9s 248ms/step - loss: 0.0058 - root_mean_squared_error: 0.6448 - val_loss: 0.9321 - val_root_mean_squared_error: 0.9655\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 9s 256ms/step - loss: 0.0056 - root_mean_squared_error: 0.6211 - val_loss: 0.8983 - val_root_mean_squared_error: 0.9478\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0058 - root_mean_squared_error: 0.6281Restoring model weights from the end of the best epoch: 1.\n",
      "37/37 [==============================] - 10s 258ms/step - loss: 0.0058 - root_mean_squared_error: 0.6281 - val_loss: 0.9424 - val_root_mean_squared_error: 0.9708\n",
      "Epoch 00006: early stopping\n",
      "45\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 16s 262ms/step - loss: 0.0060 - root_mean_squared_error: 0.6433 - val_loss: 0.9349 - val_root_mean_squared_error: 0.9669\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 9s 256ms/step - loss: 0.0057 - root_mean_squared_error: 0.6299 - val_loss: 0.9035 - val_root_mean_squared_error: 0.9505\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 9s 254ms/step - loss: 0.0050 - root_mean_squared_error: 0.6185 - val_loss: 0.9383 - val_root_mean_squared_error: 0.9687\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 9s 245ms/step - loss: 0.0057 - root_mean_squared_error: 0.6208 - val_loss: 0.9522 - val_root_mean_squared_error: 0.9758\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 9s 253ms/step - loss: 0.0048 - root_mean_squared_error: 0.6140 - val_loss: 0.9008 - val_root_mean_squared_error: 0.9491\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 9s 245ms/step - loss: 0.0047 - root_mean_squared_error: 0.6110 - val_loss: 0.9618 - val_root_mean_squared_error: 0.9807\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 9s 246ms/step - loss: 0.0058 - root_mean_squared_error: 0.6254 - val_loss: 0.9024 - val_root_mean_squared_error: 0.9500\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 9s 245ms/step - loss: 0.0046 - root_mean_squared_error: 0.5949 - val_loss: 0.9952 - val_root_mean_squared_error: 0.9976\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - 9s 247ms/step - loss: 0.0050 - root_mean_squared_error: 0.6484 - val_loss: 0.9167 - val_root_mean_squared_error: 0.9574\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0049 - root_mean_squared_error: 0.6160Restoring model weights from the end of the best epoch: 5.\n",
      "37/37 [==============================] - 10s 260ms/step - loss: 0.0049 - root_mean_squared_error: 0.6160 - val_loss: 0.9172 - val_root_mean_squared_error: 0.9577\n",
      "Epoch 00010: early stopping\n",
      "46\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 15s 291ms/step - loss: 0.0051 - root_mean_squared_error: 0.6335 - val_loss: 0.9108 - val_root_mean_squared_error: 0.9544\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 10s 259ms/step - loss: 0.0052 - root_mean_squared_error: 0.6180 - val_loss: 0.9126 - val_root_mean_squared_error: 0.9553\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 10s 262ms/step - loss: 0.0061 - root_mean_squared_error: 0.6235 - val_loss: 0.9830 - val_root_mean_squared_error: 0.9914\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 10s 263ms/step - loss: 0.0050 - root_mean_squared_error: 0.6053 - val_loss: 0.9478 - val_root_mean_squared_error: 0.9736\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 10s 266ms/step - loss: 0.0064 - root_mean_squared_error: 0.6614 - val_loss: 0.9266 - val_root_mean_squared_error: 0.9626\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0052 - root_mean_squared_error: 0.6269Restoring model weights from the end of the best epoch: 1.\n",
      "37/37 [==============================] - 10s 268ms/step - loss: 0.0052 - root_mean_squared_error: 0.6269 - val_loss: 0.9561 - val_root_mean_squared_error: 0.9778\n",
      "Epoch 00006: early stopping\n",
      "47\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 280ms/step - loss: 0.0052 - root_mean_squared_error: 0.6167 - val_loss: 0.9031 - val_root_mean_squared_error: 0.9503\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 10s 258ms/step - loss: 0.0044 - root_mean_squared_error: 0.6099 - val_loss: 0.9680 - val_root_mean_squared_error: 0.9839\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 10s 264ms/step - loss: 0.0056 - root_mean_squared_error: 0.6254 - val_loss: 0.9525 - val_root_mean_squared_error: 0.9760\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 10s 262ms/step - loss: 0.0059 - root_mean_squared_error: 0.6487 - val_loss: 0.9650 - val_root_mean_squared_error: 0.9824\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 9s 252ms/step - loss: 0.0051 - root_mean_squared_error: 0.6136 - val_loss: 0.9061 - val_root_mean_squared_error: 0.9519\n",
      "Epoch 6/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.0047 - root_mean_squared_error: 0.6081Restoring model weights from the end of the best epoch: 1.\n",
      "37/37 [==============================] - 10s 264ms/step - loss: 0.0047 - root_mean_squared_error: 0.6081 - val_loss: 0.9412 - val_root_mean_squared_error: 0.9702\n",
      "Epoch 00006: early stopping\n",
      "48\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 15s 287ms/step - loss: 0.0043 - root_mean_squared_error: 0.5984 - val_loss: 0.9183 - val_root_mean_squared_error: 0.9583\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 10s 264ms/step - loss: 0.0051 - root_mean_squared_error: 0.6285 - val_loss: 0.8693 - val_root_mean_squared_error: 0.9324\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 10s 260ms/step - loss: 0.0053 - root_mean_squared_error: 0.6266 - val_loss: 0.9097 - val_root_mean_squared_error: 0.9538\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 10s 269ms/step - loss: 0.0051 - root_mean_squared_error: 0.6232 - val_loss: 0.9085 - val_root_mean_squared_error: 0.9531\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 9s 255ms/step - loss: 0.0055 - root_mean_squared_error: 0.6267 - val_loss: 0.9943 - val_root_mean_squared_error: 0.9971\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 10s 261ms/step - loss: 0.0057 - root_mean_squared_error: 0.6738 - val_loss: 1.0088 - val_root_mean_squared_error: 1.0044\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0057 - root_mean_squared_error: 0.6441Restoring model weights from the end of the best epoch: 2.\n",
      "37/37 [==============================] - 10s 265ms/step - loss: 0.0057 - root_mean_squared_error: 0.6441 - val_loss: 1.0345 - val_root_mean_squared_error: 1.0171\n",
      "Epoch 00007: early stopping\n",
      "49\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 14s 281ms/step - loss: 0.0047 - root_mean_squared_error: 0.6198 - val_loss: 0.9106 - val_root_mean_squared_error: 0.9543\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 10s 268ms/step - loss: 0.0057 - root_mean_squared_error: 0.6367 - val_loss: 0.8829 - val_root_mean_squared_error: 0.9396\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 10s 263ms/step - loss: 0.0052 - root_mean_squared_error: 0.6382 - val_loss: 0.9234 - val_root_mean_squared_error: 0.9609\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 10s 258ms/step - loss: 0.0055 - root_mean_squared_error: 0.6440 - val_loss: 0.8962 - val_root_mean_squared_error: 0.9467\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 9s 254ms/step - loss: 0.0057 - root_mean_squared_error: 0.6552 - val_loss: 0.9074 - val_root_mean_squared_error: 0.9526\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 10s 262ms/step - loss: 0.0046 - root_mean_squared_error: 0.6145 - val_loss: 0.9322 - val_root_mean_squared_error: 0.9655\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0054 - root_mean_squared_error: 0.6053Restoring model weights from the end of the best epoch: 2.\n",
      "37/37 [==============================] - 10s 267ms/step - loss: 0.0054 - root_mean_squared_error: 0.6053 - val_loss: 0.9253 - val_root_mean_squared_error: 0.9619\n",
      "Epoch 00007: early stopping\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "maxv = 0.36\n",
    "idx = 0\n",
    "output = pd.DataFrame()\n",
    "for i in range(50):\n",
    "    model_name = 'model weight/'+var+'/attend-text1_'+var+'-best.h5'\n",
    "    model.load_weights(model_name)\n",
    "    num_warmup_steps = 0\n",
    "    init_lr = 1e-5\n",
    "    optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                              num_train_steps=num_train_steps,\n",
    "                                              num_warmup_steps=num_warmup_steps,\n",
    "                                              optimizer_type='adamw')\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=tf.keras.losses.MeanSquaredError(),\n",
    "                  metrics= tf.keras.metrics.RootMeanSquaredError())\n",
    "\n",
    "    early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "        patience=5,\n",
    "    #     patience=5,\n",
    "        monitor=\"val_loss\",\n",
    "        restore_best_weights=True,\n",
    "        verbose=1)\n",
    "    training_history = model.fit(\n",
    "        x = [tf.constant(train_text),train_emb],\n",
    "    #     x = x_train,\n",
    "        # x = tf.constant(train_text),\n",
    "        y = {'out4':np.array(train_cost)},\n",
    "        sample_weight={'out4': np.array(weights)},\n",
    "        epochs=epochs,\n",
    "        batch_size = batch_size,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=(\n",
    "            [tf.constant(val_text),val_emb],\n",
    "    #                      x_val,\n",
    "            # tf.constant(val_text),\n",
    "            {'out4':np.array(val_cost)}),\n",
    "        callbacks=[early_stopping_callback]\n",
    "    )\n",
    "    test_results0 = model.predict([tf.constant(test_text),test_emb])\n",
    "    test_result= test_results0.reshape(len(test_text)).tolist()\n",
    "    test_cost = test_df[var]\n",
    "\n",
    "    difference_array = np.subtract(test_result, test_cost)\n",
    "    squared_array = np.square(difference_array)\n",
    "    mse = squared_array.mean()\n",
    "\n",
    "    correlation_matrix = np.corrcoef(test_cost, test_result)\n",
    "    correlation_xy = correlation_matrix[0,1]\n",
    "    r_squared = correlation_xy**2\n",
    "\n",
    "    output.loc[idx,'warm up'] = a\n",
    "    output.loc[idx,'var'] = var\n",
    "    output.loc[idx,'lr'] = init_lr\n",
    "    output.loc[idx,'mse'] = mse\n",
    "    output.loc[idx,'r^2'] = r_squared\n",
    "    idx += 1\n",
    "    print (idx)\n",
    "    if r_squared > maxv:\n",
    "        model_name1 = 'model weight/'+var+'/attend-text1_'+var+'-best.h5'\n",
    "        model.save_weights(model_name1)\n",
    "        maxv = r_squared\n",
    "        print (r_squared)\n",
    "#         if r_squared > 0.222:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cj7iRDbCYiZu"
   },
   "outputs": [],
   "source": [
    "# sketch1 = sketch1.astype({\"text\": str})\n",
    "# text = list(sketch1['text'])\n",
    "\n",
    "# from keras import backend as K\n",
    "# sec_last = model.layers[3]\n",
    "# get_output = K.function([model.layers[0].input, ],[sec_last.output, model.layers[-1].output])\n",
    "# [emb_text, predictions] = get_output(tf.constant(text))\n",
    "\n",
    "# np.savetxt('text emb 1-'+var, emb_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kTjFvt98c0WY"
   },
   "outputs": [],
   "source": [
    "# ##to test which BEET\n",
    "# idx = 0\n",
    "# output = pd.DataFrame()\n",
    "# for key in map_name_to_handle.keys():\n",
    "#     bert_model_name = key\n",
    "#     tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "#     tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]   \n",
    "#     text_input = Input(shape=(), dtype=tf.string, name='text')\n",
    "#     preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "#     encoder_inputs = preprocessing_layer(text_input)\n",
    "#     encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "#     outputs = encoder(encoder_inputs)\n",
    "#     net = outputs['pooled_output']\n",
    "#     # net = layers.Dropout(0.1)(net)\n",
    "#     net = layers.Dense(128, activation='relu')(net)\n",
    "#     net = layers.Dropout(0.1)(net)\n",
    "#     out1y = layers.Dense(1, activation='relu', name='out1y')(net)\n",
    "#     model = Model(text_input, out1y)\n",
    "\n",
    "#     model.compile(optimizer=optimizer,\n",
    "#                   loss=tf.keras.losses.MeanSquaredError(),\n",
    "#                   metrics= tf.keras.metrics.RootMeanSquaredError())\n",
    "#     training_history = model.fit(\n",
    "#         x = tf.constant(train_text),\n",
    "#         y = {'out1y':np.array(train_cost)},\n",
    "#         sample_weight={'out1y': np.array(weights)},\n",
    "#         epochs=epochs,\n",
    "#         batch_size = batch_size,\n",
    "#         steps_per_epoch=steps_per_epoch,\n",
    "#         validation_data=(\n",
    "#             tf.constant(val_text),\n",
    "#             {'out1y':np.array(val_cost)}),\n",
    "#         callbacks=[early_stopping_callback]\n",
    "#     )\n",
    "\n",
    "#     test_results0 = model.predict(tf.constant(test_text))\n",
    "#     test_result= test_results0.reshape(len(test_text)).tolist()\n",
    "#     test_cost = test_df[var]\n",
    "\n",
    "#     difference_array = np.subtract(test_result, test_cost)\n",
    "#     squared_array = np.square(difference_array)\n",
    "#     mse = squared_array.mean()\n",
    "\n",
    "#     correlation_matrix = np.corrcoef(test_cost, test_result)\n",
    "#     correlation_xy = correlation_matrix[0,1]\n",
    "#     r_squared = correlation_xy**2\n",
    "\n",
    "#     output.loc[idx,'n'] = idx\n",
    "#     output.loc[idx,'var'] = var\n",
    "#     output.loc[idx,'lr'] = init_lr\n",
    "#     output.loc[idx,'mse'] = mse\n",
    "#     output.loc[idx,'r^2'] = r_squared\n",
    "#     output.loc[idx,'model'] = key\n",
    "#     idx += 1\n",
    "#     print (key+\":  \", r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "attention - sketch on text.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "tf-transf",
   "language": "python",
   "name": "tf-transf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
